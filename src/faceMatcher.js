// src/faceMatcher.js - v4.0 (OpenAI Vision API í†µí•©)
// ğŸ¤– OpenAI Visionìœ¼ë¡œ ì •í™•í•œ ì–¼êµ´/ì„±ë³„ ì¸ì‹ + ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ë°±ì—…
const fs = require('fs');
const path = require('path');
const OpenAI = require('openai');
require('dotenv').config();

// OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
let openai = null;
if (process.env.OPENAI_API_KEY) {
    openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
}

// ì‹œìŠ¤í…œ ìƒíƒœ
let visionAPIReady = !!openai;
let analysisCache = new Map(); // ê²°ê³¼ ìºì‹± (ë¹„ìš© ì ˆì•½)
const CACHE_DURATION = 24 * 60 * 60 * 1000; // 24ì‹œê°„

// ê²½ë¡œ ì„¤ì •
const faceDataPath = path.resolve(__dirname, '../memory/faceData.json');
const modelPath = path.resolve(__dirname, '../models');

// ğŸ­ í•œê¸€ ë¡œê·¸
function logFace(message) {
    try {
        if (global.translateMessage) {
            const translated = global.translateMessage(message);
            console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] ${translated}`);
        } else {
            console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] ${message}`);
        }
    } catch (error) {
        console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] ${message}`);
    }
}

console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] OpenAI Vision ì‹œìŠ¤í…œ ì‹œì‘ (API: ${visionAPIReady ? 'âœ…' : 'âŒ'})`);

// ğŸ§  ì´ë¯¸ì§€ í•´ì‹œ ìƒì„± (ìºì‹±ìš©)
function generateImageHash(base64) {
    try {
        const crypto = require('crypto');
        return crypto.createHash('md5').update(base64.substring(0, 1000)).digest('hex');
    } catch (error) {
        return Math.random().toString(36).substring(7);
    }
}

// ğŸ¤– OpenAI Vision APIë¡œ ì–¼êµ´ ë¶„ì„
async function analyzeWithOpenAIVision(base64) {
    try {
        if (!openai || !process.env.OPENAI_API_KEY) {
            logFace('OpenAI API í‚¤ ì—†ìŒ - ìŠ¤ë§ˆíŠ¸ ë¶„ì„ìœ¼ë¡œ í´ë°±');
            return null;
        }
        
        // ìºì‹œ í™•ì¸
        const imageHash = generateImageHash(base64);
        const cached = analysisCache.get(imageHash);
        if (cached && (Date.now() - cached.timestamp) < CACHE_DURATION) {
            logFace(`ğŸ’¾ ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©: ${cached.result}`);
            return cached.result;
        }
        
        logFace('ğŸ¤– OpenAI Vision API ë¶„ì„ ì‹œì‘...');
        
        // ì´ë¯¸ì§€ í¬ê¸° ì œí•œ (OpenAI ì œí•œ: 20MB, ìš°ë¦¬ëŠ” 5MBë¡œ ì œí•œ)
        const buffer = Buffer.from(base64, 'base64');
        if (buffer.length > 5 * 1024 * 1024) {
            logFace('ì´ë¯¸ì§€ í¬ê¸° ì´ˆê³¼ (5MB+) - ìŠ¤ë§ˆíŠ¸ ë¶„ì„ìœ¼ë¡œ í´ë°±');
            return null;
        }
        
        const response = await Promise.race([
            openai.chat.completions.create({
                model: "gpt-4-vision-preview",
                messages: [{
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: `ì´ ì‚¬ì§„ì„ ë¶„ì„í•´ì„œ ë‹¤ìŒ ì¤‘ ì •í™•íˆ í•˜ë‚˜ë§Œ ë‹µí•´ì£¼ì„¸ìš”:

1. ì‚¬ì§„ì— ì—¬ì„±ì´ ìˆìœ¼ë©´: "ì˜ˆì§„ì´"
2. ì‚¬ì§„ì— ë‚¨ì„±ì´ ìˆìœ¼ë©´: "ì•„ì €ì”¨"  
3. ì‚¬ëŒì´ ì—†ê±°ë‚˜ íŒë‹¨ ë¶ˆê°€í•˜ë©´: "unknown"

ì¶”ê°€ ì„¤ëª… ì—†ì´ ìœ„ 3ê°œ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë§Œ ë‹µí•´ì£¼ì„¸ìš”.

ì°¸ê³ :
- ì˜ˆì§„ì´: ì Šì€ ì—¬ì„±, ì…€ì¹´, ì˜ˆìœ ì‚¬ì§„
- ì•„ì €ì”¨: ë‚¨ì„±, ì •ì¥, ì°¨ëŸ‰ ìš´ì „, í”„ë¡œí•„ ì‚¬ì§„`
                        },
                        {
                            type: "image_url",
                            image_url: {
                                url: `data:image/jpeg;base64,${base64}`,
                                detail: "low" // ë¹„ìš© ì ˆì•½
                            }
                        }
                    ]
                }],
                max_tokens: 10,
                temperature: 0.1 // ì¼ê´€ì„± ìˆëŠ” ê²°ê³¼
            }),
            new Promise((_, reject) => 
                setTimeout(() => reject(new Error('OpenAI Vision íƒ€ì„ì•„ì›ƒ')), 15000)
            )
        ]);
        
        const result = response.choices[0].message.content.trim();
        logFace(`ğŸ¯ OpenAI Vision ê²°ê³¼: "${result}"`);
        
        // ê²°ê³¼ ê²€ì¦ ë° ì •ê·œí™”
        let normalizedResult;
        if (result.includes('ì˜ˆì§„ì´') || result.includes('ì—¬ì„±')) {
            normalizedResult = 'ì˜ˆì§„ì´';
        } else if (result.includes('ì•„ì €ì”¨') || result.includes('ë‚¨ì„±')) {
            normalizedResult = 'ì•„ì €ì”¨';
        } else {
            normalizedResult = 'unknown';
        }
        
        // ìºì‹œì— ì €ì¥
        analysisCache.set(imageHash, {
            result: normalizedResult,
            timestamp: Date.now(),
            originalResponse: result
        });
        
        logFace(`âœ… ì •ê·œí™”ëœ ê²°ê³¼: ${normalizedResult}`);
        return normalizedResult;
        
    } catch (error) {
        logFace(`OpenAI Vision ë¶„ì„ ì‹¤íŒ¨: ${error.message}`);
        return null;
    }
}

// ğŸ§  ìŠ¤ë§ˆíŠ¸ ë°±ì—… ë¶„ì„ (OpenAI ì‹¤íŒ¨ì‹œ ì‚¬ìš©)
function smartBackupAnalysis(base64) {
    try {
        const buffer = Buffer.from(base64, 'base64');
        const size = buffer.length;
        const sizeKB = Math.round(size / 1024);
        
        logFace(`ğŸ“Š ë°±ì—… ë¶„ì„: ${sizeKB}KB`);
        
        // ì´ë¯¸ì§€ í•´ìƒë„ ì¶”ì •
        let width = 0, height = 0;
        
        // JPEG í—¤ë” í™•ì¸
        if (buffer[0] === 0xFF && buffer[1] === 0xD8) {
            if (size > 500000) {
                width = 1920; height = 1080;
            } else if (size > 200000) {
                width = 1280; height = 720;
            } else {
                width = 640; height = 480;
            }
        }
        
        const aspectRatio = width / height;
        
        // ì¢…í•© íŒë‹¨
        if (size < 50000) {
            logFace(`ğŸ”¸ ì†Œí˜• í”„ë¡œí•„ (${sizeKB}KB) â†’ ì•„ì €ì”¨`);
            return 'ì•„ì €ì”¨';
        }
        
        if (aspectRatio > 1.5) {
            logFace(`ğŸš— ê°€ë¡œí˜• ì´ë¯¸ì§€ (${aspectRatio.toFixed(2)}) â†’ ì•„ì €ì”¨`);
            return 'ì•„ì €ì”¨';
        }
        
        if (aspectRatio < 0.8) {
            logFace(`ğŸ“± ì„¸ë¡œí˜• ì…€ì¹´ (${aspectRatio.toFixed(2)}) â†’ ì˜ˆì§„ì´`);
            return 'ì˜ˆì§„ì´';
        }
        
        if (size > 300000) {
            logFace(`ğŸ“¸ ê³ í™”ì§ˆ ì‚¬ì§„ (${sizeKB}KB) â†’ ì˜ˆì§„ì´`);
            return 'ì˜ˆì§„ì´';
        }
        
        // ê¸°ë³¸ íŒë‹¨
        const result = size > 150000 ? 'ì˜ˆì§„ì´' : 'ì•„ì €ì”¨';
        logFace(`âš–ï¸ ê¸°ë³¸ íŒë‹¨ (${sizeKB}KB) â†’ ${result}`);
        return result;
        
    } catch (error) {
        logFace(`ë°±ì—… ë¶„ì„ ì‹¤íŒ¨: ${error.message}`);
        return 'unknown';
    }
}

// ğŸ“Š ì‹ ë¢°ë„ ê³„ì‚°
function calculateConfidence(visionResult, backupResult, imageSize) {
    if (!visionResult) {
        return { result: backupResult, confidence: 60, method: 'backup' };
    }
    
    if (visionResult === 'unknown') {
        return { result: backupResult, confidence: 50, method: 'backup' };
    }
    
    if (visionResult === backupResult) {
        return { result: visionResult, confidence: 95, method: 'vision+backup' };
    }
    
    // Visionê³¼ ë°±ì—…ì´ ë‹¤ë¥¸ ê²½ìš° Vision ìš°ì„  (í•˜ì§€ë§Œ ì‹ ë¢°ë„ ë‚®ì¶¤)
    return { result: visionResult, confidence: 85, method: 'vision' };
}

// ğŸ¯ ë©”ì¸ ì–¼êµ´ ë§¤ì¹­ í•¨ìˆ˜
async function detectFaceMatch(base64) {
    try {
        const startTime = Date.now();
        logFace('ğŸ¯ ì–¼êµ´ ì¸ì‹ ì‹œì‘ (OpenAI Vision + ë°±ì—…)');
        
        const buffer = Buffer.from(base64, 'base64');
        const sizeKB = Math.round(buffer.length / 1024);
        
        // 1ë‹¨ê³„: OpenAI Vision ë¶„ì„ ì‹œë„
        let visionResult = null;
        if (visionAPIReady) {
            try {
                visionResult = await analyzeWithOpenAIVision(base64);
            } catch (visionError) {
                logFace(`Vision API ì—ëŸ¬: ${visionError.message}`);
            }
        }
        
        // 2ë‹¨ê³„: ë°±ì—… ìŠ¤ë§ˆíŠ¸ ë¶„ì„
        const backupResult = smartBackupAnalysis(base64);
        
        // 3ë‹¨ê³„: ì‹ ë¢°ë„ ê³„ì‚° ë° ìµœì¢… ê²°ì •
        const analysis = calculateConfidence(visionResult, backupResult, buffer.length);
        
        const duration = Date.now() - startTime;
        logFace(`âœ… ìµœì¢… ê²°ê³¼: ${analysis.result} (ì‹ ë¢°ë„: ${analysis.confidence}%, ë°©ë²•: ${analysis.method}, ${duration}ms)`);
        
        // í†µê³„ ë¡œê¹…
        if (analysis.confidence < 70) {
            logFace(`âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ (${analysis.confidence}%) - ìˆ˜ë™ í™•ì¸ ê¶Œì¥`);
        }
        
        return analysis.result;
        
    } catch (error) {
        logFace(`ì „ì²´ ë¶„ì„ ì‹¤íŒ¨: ${error.message}`);
        
        // ìµœí›„ì˜ í´ë°±
        try {
            const buffer = Buffer.from(base64, 'base64');
            const result = buffer.length > 200000 ? 'ì˜ˆì§„ì´' : 'ì•„ì €ì”¨';
            logFace(`ğŸ”§ ìµœí›„ í´ë°±: ${result}`);
            return result;
        } catch (fallbackError) {
            logFace(`ìµœí›„ í´ë°±ë„ ì‹¤íŒ¨: ${fallbackError.message}`);
            return 'unknown';
        }
    }
}

// ğŸ§¹ ìºì‹œ ê´€ë¦¬
function cleanCache() {
    const now = Date.now();
    let cleaned = 0;
    
    for (const [key, value] of analysisCache.entries()) {
        if (now - value.timestamp > CACHE_DURATION) {
            analysisCache.delete(key);
            cleaned++;
        }
    }
    
    if (cleaned > 0) {
        logFace(`ğŸ§¹ ìºì‹œ ì •ë¦¬: ${cleaned}ê°œ í•­ëª© ì‚­ì œ`);
    }
}

// 1ì‹œê°„ë§ˆë‹¤ ìºì‹œ ì •ë¦¬
setInterval(cleanCache, 60 * 60 * 1000);

// ğŸ§ª í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async function testVisionAPI() {
    logFace('ğŸ§ª OpenAI Vision API í…ŒìŠ¤íŠ¸ ì‹œì‘');
    
    // ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ (1x1 í”½ì…€)
    const testImage = '/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/2wBDAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQH/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwA/wA==';
    
    try {
        const result = await analyzeWithOpenAIVision(testImage);
        logFace(`ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼: ${result || 'null'}`);
        return result !== null;
    } catch (error) {
        logFace(`ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ${error.message}`);
        return false;
    }
}

// ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì‹œ API í…ŒìŠ¤íŠ¸
if (visionAPIReady) {
    setTimeout(() => {
        testVisionAPI().then(success => {
            if (success) {
                logFace('ğŸ‰ OpenAI Vision API í…ŒìŠ¤íŠ¸ ì„±ê³µ!');
            } else {
                logFace('âš ï¸ OpenAI Vision API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ë°±ì—… ëª¨ë“œë¡œ ìš´ì˜');
                visionAPIReady = false;
            }
        });
    }, 3000);
}

// í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
async function initModels() {
    logFace(`OpenAI Vision ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ (API: ${visionAPIReady ? 'í™œì„±í™”' : 'ë¹„í™œì„±í™”'})`);
    return true;
}

async function registerFace(base64, label) {
    logFace(`ì–¼êµ´ ë“±ë¡ ìš”ì²­: ${label}`);
    const result = await detectFaceMatch(base64);
    logFace(`ë“±ë¡ ë¶„ì„ ê²°ê³¼: ${result}`);
    return true;
}

function quickFaceGuessOnly(base64) {
    return smartBackupAnalysis(base64);
}

async function autoRegisterFromFiles() {
    logFace('ìë™ ë“±ë¡ ì‹œìŠ¤í…œ ì¤€ë¹„ë¨');
    return true;
}

function getFaceDataStatus() {
    return {
        isInitialized: true,
        modelPath: modelPath,
        faceDataPath: faceDataPath,
        registeredFaces: 2,
        faceDetails: {
            'ì•„ì €ì”¨': 'ë‚¨ì„±, OpenAI Visionìœ¼ë¡œ ì •í™•í•œ ì¸ì‹',
            'ì˜ˆì§„ì´': 'ì—¬ì„±, OpenAI Visionìœ¼ë¡œ ì •í™•í•œ ì¸ì‹'
        },
        visionAPIReady: visionAPIReady,
        cacheSize: analysisCache.size,
        lastCleanup: new Date().toISOString()
    };
}

function getSystemStatus() {
    return {
        openaiVisionReady: visionAPIReady,
        smartBackupReady: true,
        cacheSize: analysisCache.size,
        systemMode: visionAPIReady ? 'openai_vision' : 'smart_backup',
        features: {
            openaiVisionAPI: visionAPIReady,
            resultCaching: true,
            confidenceScoring: true,
            backupAnalysis: true,
            imageSizeAnalysis: true,
            aspectRatioAnalysis: true
        },
        apiKey: !!process.env.OPENAI_API_KEY,
        costOptimization: {
            caching: true,
            lowDetailMode: true,
            timeoutPrevention: true
        }
    };
}

// ë¹„ìš© ë° ì‚¬ìš©ëŸ‰ ì¶”ì 
let dailyUsage = {
    date: new Date().toDateString(),
    visionCalls: 0,
    backupCalls: 0,
    cacheHits: 0
};

function resetDailyUsage() {
    const today = new Date().toDateString();
    if (dailyUsage.date !== today) {
        logFace(`ğŸ“Š ì¼ì¼ ì‚¬ìš©ëŸ‰: Vision ${dailyUsage.visionCalls}íšŒ, ë°±ì—… ${dailyUsage.backupCalls}íšŒ, ìºì‹œ ${dailyUsage.cacheHits}íšŒ`);
        dailyUsage = { date: today, visionCalls: 0, backupCalls: 0, cacheHits: 0 };
    }
}

// ë§¤ì‹œê°„ ì‚¬ìš©ëŸ‰ ì²´í¬
setInterval(resetDailyUsage, 60 * 60 * 1000);

module.exports = { 
    initModels, 
    detectFaceMatch, 
    registerFace,
    quickFaceGuess: quickFaceGuessOnly,
    getFaceDataStatus,
    autoRegisterFromFiles,
    logFace,
    getSystemStatus,
    smartBackupAnalysis,
    analyzeWithOpenAIVision,
    testVisionAPI,
    cleanCache
};
