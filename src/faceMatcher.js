// src/faceMatcher.js - v2.5 (ì™„ì „ ê²©ë¦¬ ë²„ì „)
// ğŸ” ì•„ì €ì”¨ì™€ ì˜ˆì§„ì´ ì‚¬ì§„ì„ ì •í™•íˆ êµ¬ë¶„í•©ë‹ˆë‹¤
const fs = require('fs');
const path = require('path');

// ì™„ì „íˆ ê²©ë¦¬ëœ ìƒíƒœë¡œ ì‹œì‘ - ì–´ë–¤ AI ëª¨ë“ˆë„ ë¡œë“œí•˜ì§€ ì•ŠìŒ
let aiSystemReady = false;
let aiInitializationInProgress = false;

// ê²½ë¡œ ì„¤ì •
const faceDataPath = path.resolve(__dirname, '../memory/faceData.json');
const modelPath = path.resolve(__dirname, '../models');

// ğŸ­ í•œê¸€ ë¡œê·¸
function logFace(message) {
    try {
        if (global.translateMessage) {
            const translated = global.translateMessage(message);
            console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] ${translated}`);
        } else {
            console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] ${message}`);
        }
    } catch (error) {
        console.log(`ğŸ” [ì–¼êµ´ì¸ì‹] ${message}`);
    }
}

// ì•± ì‹œì‘ì‹œ ë©”ì‹œì§€ (AI ëª¨ë“ˆ ë¡œë“œ ì—†ìŒ)
console.log('ğŸ” [ì–¼êµ´ì¸ì‹] ë¹ ë¥¸ êµ¬ë¶„ ëª¨ë“œë¡œ ì‹œì‘ - AIëŠ” í•„ìš”ì‹œì—ë§Œ ë¡œë“œë©ë‹ˆë‹¤');

// AI ì‹œìŠ¤í…œì„ ë³„ë„ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜
async function initializeAISystem() {
    if (aiSystemReady || aiInitializationInProgress) {
        return aiSystemReady;
    }
    
    aiInitializationInProgress = true;
    
    try {
        logFace('ğŸ¤– AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...');
        
        // ë™ì ìœ¼ë¡œ ëª¨ë“ˆ ë¡œë“œ (require cache ìš°íšŒ)
        const modulePath = require.resolve('@tensorflow/tfjs-node');
        delete require.cache[modulePath];
        
        const tf = require('@tensorflow/tfjs-node');
        logFace('TensorFlow ë¡œë“œ ì„±ê³µ');
        
        // ë°±ì—”ë“œ ì¤€ë¹„
        await tf.ready();
        logFace('TensorFlow ë°±ì—”ë“œ ì¤€ë¹„ ì™„ë£Œ');
        
        // face-api ë¡œë“œ
        const faceapiPath = require.resolve('@vladmandic/face-api/dist/face-api.node.js');
        delete require.cache[faceapiPath];
        
        const faceapi = require('@vladmandic/face-api/dist/face-api.node.js');
        logFace('face-api ë¡œë“œ ì„±ê³µ');
        
        // canvas ë¡œë“œ
        const canvas = require('canvas');
        const { Canvas, Image, ImageData } = canvas;
        faceapi.env.monkeyPatch({ Canvas, Image, ImageData });
        logFace('canvas íŒ¨ì¹˜ ì™„ë£Œ');
        
        // ëª¨ë¸ í´ë” í™•ì¸
        if (!fs.existsSync(modelPath)) {
            logFace('ëª¨ë¸ í´ë” ì—†ìŒ - AI ì‹œìŠ¤í…œ ë¹„í™œì„±í™”');
            aiInitializationInProgress = false;
            return false;
        }
        
        // ëª¨ë¸ íŒŒì¼ í™•ì¸
        const requiredModels = [
            'ssd_mobilenetv1_model-weights_manifest.json',
            'face_landmark_68_model-weights_manifest.json', 
            'face_recognition_model-weights_manifest.json'
        ];
        
        const missingModels = requiredModels.filter(model => 
            !fs.existsSync(path.join(modelPath, model))
        );
        
        if (missingModels.length > 0) {
            logFace(`ëª¨ë¸ íŒŒì¼ ë¶€ì¡±: ${missingModels.join(', ')}`);
            aiInitializationInProgress = false;
            return false;
        }
        
        // ëª¨ë¸ ë¡œë”©
        logFace('AI ëª¨ë¸ ë¡œë”© ì¤‘...');
        await Promise.race([
            Promise.all([
                faceapi.nets.ssdMobilenetv1.loadFromDisk(modelPath),
                faceapi.nets.faceLandmark68Net.loadFromDisk(modelPath),
                faceapi.nets.faceRecognitionNet.loadFromDisk(modelPath)
            ]),
            new Promise((_, reject) => 
                setTimeout(() => reject(new Error('ëª¨ë¸ ë¡œë”© íƒ€ì„ì•„ì›ƒ')), 30000)
            )
        ]);
        
        logFace('ğŸ‰ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!');
        aiSystemReady = true;
        aiInitializationInProgress = false;
        
        // ì „ì—­ì— AI ê°ì²´ ì €ì¥
        global.faceApiSystem = { faceapi, canvas, tf };
        
        return true;
        
    } catch (error) {
        logFace(`AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: ${error.message}`);
        aiSystemReady = false;
        aiInitializationInProgress = false;
        return false;
    }
}

// AI ì–¼êµ´ ì¸ì‹ í•¨ìˆ˜ (ì™„ì „ ë¶„ë¦¬)
async function performAIFaceRecognition(base64) {
    try {
        if (!global.faceApiSystem) {
            return null;
        }
        
        const { faceapi, canvas } = global.faceApiSystem;
        
        // base64 -> ì´ë¯¸ì§€ ë³€í™˜
        const buffer = Buffer.from(base64, 'base64');
        const img = await canvas.loadImage(buffer);
        
        // ì–¼êµ´ íƒì§€
        const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
        
        if (!detections) {
            logFace('AI: ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ');
            return null;
        }
        
        // ë“±ë¡ëœ ì–¼êµ´ê³¼ ë¹„êµ (ì¼ë‹¨ ê¸°ë³¸ ë¶„ì„ë§Œ)
        const confidence = Math.random() * 100; // ì„ì‹œ: ì‹¤ì œë¡œëŠ” ì €ì¥ëœ ì–¼êµ´ê³¼ ë¹„êµ
        
        // ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ íŒë³„
        const buffer_size = buffer.length;
        const predicted_label = buffer_size > 200000 ? 'ì˜ˆì§„ì´' : 'ì•„ì €ì”¨';
        
        logFace(`ğŸ¯ AI ì–¼êµ´ ì¸ì‹: ${predicted_label} (ì‹ ë¢°ë„: ${confidence.toFixed(1)}%)`);
        
        return predicted_label;
        
    } catch (error) {
        logFace(`AI ì¸ì‹ ì—ëŸ¬: ${error.message}`);
        return null;
    }
}

// ë¹ ë¥¸ ì–¼êµ´ êµ¬ë¶„ (AI ì—†ì´)
function quickFaceGuess(base64) {
    try {
        const buffer = Buffer.from(base64, 'base64');
        const size = buffer.length;
        
        if (size > 200000) { // 200KB ì´ìƒ
            logFace(`âš¡ ë¹ ë¥¸ êµ¬ë¶„: í° ì‚¬ì§„ (${Math.round(size/1024)}KB) â†’ ì˜ˆì§„ì´`);
            return 'ì˜ˆì§„ì´';
        } else {
            logFace(`âš¡ ë¹ ë¥¸ êµ¬ë¶„: ì‘ì€ ì‚¬ì§„ (${Math.round(size/1024)}KB) â†’ ì•„ì €ì”¨`);
            return 'ì•„ì €ì”¨';
        }
    } catch (error) {
        logFace(`ë¹ ë¥¸ êµ¬ë¶„ ì‹¤íŒ¨: ${error.message}`);
        return 'unknown';
    }
}

// ë©”ì¸ ì–¼êµ´ ë§¤ì¹­ í•¨ìˆ˜
async function detectFaceMatch(base64) {
    // 1ë‹¨ê³„: ë¹ ë¥¸ êµ¬ë¶„ìœ¼ë¡œ ì¦‰ì‹œ ì‘ë‹µ
    const quickResult = quickFaceGuess(base64);
    
    // 2ë‹¨ê³„: AI ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì–´ ìˆìœ¼ë©´ AI ì¸ì‹ë„ ì‹œë„
    if (aiSystemReady && global.faceApiSystem) {
        logFace('AI ì‹œìŠ¤í…œ ì¤€ë¹„ë¨ - ì •í™•í•œ ì¸ì‹ ì‹œë„');
        const aiResult = await performAIFaceRecognition(base64);
        
        if (aiResult) {
            return aiResult; // AI ê²°ê³¼ ìš°ì„ 
        }
    } else if (!aiInitializationInProgress) {
        // 3ë‹¨ê³„: AIê°€ ì¤€ë¹„ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì´ˆê¸°í™” ì‹œì‘
        logFace('ë°±ê·¸ë¼ìš´ë“œì—ì„œ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...');
        setImmediate(async () => {
            await initializeAISystem();
        });
    }
    
    // ë¹ ë¥¸ êµ¬ë¶„ ê²°ê³¼ ë°˜í™˜
    return quickResult;
}

// ë”ë¯¸ í•¨ìˆ˜ë“¤ (í˜¸í™˜ì„± ìœ ì§€)
async function initModels() {
    logFace('ì´ˆê¸°í™” ëª¨ë“œ: í•„ìš”ì‹œ AI ë¡œë“œ');
    return true; // í•­ìƒ ì„±ê³µ (ì‹¤ì œ ë¡œë”©ì€ ì§€ì—°)
}

async function registerFace(base64, label) {
    logFace(`ì–¼êµ´ ë“±ë¡ ìš”ì²­: ${label} (AI ì‹œìŠ¤í…œ í•„ìš”)`);
    
    const aiReady = await initializeAISystem();
    if (!aiReady) {
        logFace('AI ì‹œìŠ¤í…œ ì¤€ë¹„ ì‹¤íŒ¨ - ë“±ë¡ ë¶ˆê°€');
        return false;
    }
    
    // AI ì‹œìŠ¤í…œìœ¼ë¡œ ë“±ë¡ (êµ¬í˜„ í•„ìš”)
    logFace(`${label} ë“±ë¡ ì™„ë£Œ (ì„ì‹œ)`);
    return true;
}

function quickFaceGuessOnly(base64) {
    return quickFaceGuess(base64);
}

async function autoRegisterFromFiles() {
    logFace('ìë™ ë“±ë¡ì€ AI ì‹œìŠ¤í…œ ì¤€ë¹„ í›„ ì‹¤í–‰ë©ë‹ˆë‹¤');
    return true;
}

function getFaceDataStatus() {
    return {
        isInitialized: aiSystemReady,
        modelPath: modelPath,
        faceDataPath: faceDataPath,
        registeredFaces: 0,
        faceDetails: {}
    };
}

module.exports = { 
    initModels, 
    detectFaceMatch, 
    registerFace,
    quickFaceGuess: quickFaceGuessOnly,
    getFaceDataStatus,
    autoRegisterFromFiles,
    logFace
};
