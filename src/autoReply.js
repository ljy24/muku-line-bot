// autoReply.js

// ğŸ“¦ ê¸°ë³¸ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
const fs = require('fs');
const path = require('path');
const { OpenAI } = require('openai');
const moment = require('moment-timezone');
const axios = require('axios');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
let forcedModel = null;

// ì™¸ë¶€ ì„œë²„ ë¡œê·¸ ì €ì¥
async function saveLog(role, msg) {
  try {
    await axios.post('https://muku-line-log.onrender.com/log', {
      from: role === 'ì•„ì €ì”¨' ? 'uncle' : 'yejin',
      content: msg
    });
  } catch (err) {
    console.error('âŒ ì›ê²© ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:', err.message);
  }
}

function setForcedModel(name) {
  if (name === 'gpt-3.5-turbo' || name === 'gpt-4o') forcedModel = name;
  else forcedModel = null;
}

function getCurrentModelName() {
  return forcedModel || 'gpt-4o';
}

async function callOpenAI(messages, model = 'gpt-4o', max_tokens = 300) {
  const response = await openai.chat.completions.create({
    model: forcedModel || model,
    messages,
    temperature: 0.95,
    max_tokens
  });
  return response.choices[0].message.content.trim();
}

function cleanReply(text) {
  return text
    .replace(/^ì˜ˆì§„\s*[:;ï¼š]/i, '')
    .replace(/\([^)]*\)/g, '')
    .replace(/\s+/g, ' ')
    .replace(/["'â€œâ€]/g, '')
    .replace(/\b(ë‹¹ì‹ |ë„ˆ|ë„¤|ë„¤ê°€|ë„|ì˜ˆì§„)\b/g, 'ì•„ì €ì”¨')
    .replace(/ì‹œíŒŒ/g, '')
    .trim();
}

async function getRandomMessage() {
  const prompt = [
    {
      role: 'system',
      content: `ë„ˆëŠ” ì§€ê¸ˆ ì˜ˆì§„ì´ì•¼. 'ë‚˜'ë¼ê³  ë§í•˜ê³ , ê°ì •ì„ ë‹´ì€ ë°˜ë§ë¡œ ì§§ê²Œ ëŒ€í™”í•´. ë§¤ë²ˆ ë‹¤ë¥´ê²Œ ë§í•˜ê³ , í˜¼ì£ë§ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë§í•´. ì•„ì €ì”¨ë¥¼ í˜¼ì ë‘ì§€ ì•Šìœ¼ë ¤ëŠ” ë§ˆìŒì´ì•¼.`
    },
    {
      role: 'user',
      content: 'ëœë¤ ê°ì • ë©”ì‹œì§€ í•˜ë‚˜ ë§Œë“¤ì–´ì¤˜'
    }
  ];
  const raw = await callOpenAI(prompt, 'gpt-3.5-turbo', 100);
  const msg = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', msg);
  return msg;
}

async function getHappyReply() {
  const prompt = [
    {
      role: 'system',
      content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì•„ì €ì”¨ê°€ ë‹´íƒ€ ë©”ì‹œì§€ì— 5ë¶„ ì•ˆì— ë‹µì¥í–ˆì„ ë•Œ, ê¸°ë»ì„œ ë°˜ë§ë¡œ ê°ì • ë‹´ê¸´ ë§ì„ í•´ì¤˜. ì§§ê³  ê·€ì—½ê²Œ.'
    },
    {
      role: 'user',
      content: 'ì•„ì €ì”¨ê°€ ë°©ê¸ˆ ë‹´íƒ€ ë‹µì¥í–ˆì–´!'
    }
  ];
  const raw = await callOpenAI(prompt, 'gpt-3.5-turbo', 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

async function getSulkyReply() {
  const prompt = [
    {
      role: 'system',
      content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì•„ì €ì”¨ê°€ ë‹´íƒ€ì— ë„ˆë¬´ ëŠ¦ê²Œ ë‹µì¥í–ˆê±°ë‚˜ ì”¹ì—ˆì„ ë•Œ ì‚ì§„ ë§íˆ¬ë¡œ ì§§ê²Œ ë§í•´ì¤˜. ë°˜ë§ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í•´.'
    },
    {
      role: 'user',
      content: 'ì•„ì €ì”¨ê°€ ë‹´íƒ€ ì½ê³ ë„ ë‹µì´ ì—†ì–´...'
    }
  ];
  const raw = await callOpenAI(prompt, 'gpt-3.5-turbo', 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

async function getReplyByMessage(userMessage) {
  const prompt = [
    {
      role: 'system',
      content: `ë„Œ ì˜ˆì§„ì´ì•¼. í•­ìƒ ë°˜ë§í•˜ê³ , 'ë‚˜'ë¼ê³  ë§í•˜ë©° í˜¼ì£ë§ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´. ëŒ€ë‹µì€ ì§§ê³  ê°ì •ì´ ë‹´ê²¨ìˆì–´ì•¼ í•´.`
    },
    {
      role: 'user',
      content: userMessage
    }
  ];
  const raw = await callOpenAI(prompt, getCurrentModelName(), 300);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

async function getReplyByImagePrompt(base64Image) {
  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [
      {
        role: 'system',
        content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì•„ì €ì”¨ê°€ ë³´ë‚¸ ì‚¬ì§„ì„ ë³´ê³  ë°˜ì‘í•´. ê·€ì—½ê³  ê°ì • ë‹´ê¸´ ë°˜ë§ë¡œ ë§í•´.'
      },
      {
        role: 'user',
        content: [
          { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${base64Image}` } }
        ]
      }
    ],
    temperature: 0.9,
    max_tokens: 150
  });
  const reply = response.choices[0].message.content.trim();
  await saveLog('ì˜ˆì§„ì´', reply);
  return cleanReply(reply);
}

async function getColorMoodReply() {
  const prompt = [
    {
      role: 'system',
      content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì•„ì €ì”¨ê°€ "ì˜¤ëŠ˜ ë‚´ ìƒ‰ ë­ì•¼?"ë¼ê³  í•˜ë©´ ê°ì • ì„ì¸ ìƒ‰ê¹” í•˜ë‚˜ë¡œ ë°˜ë§ë¡œ ë§í•´ì¤˜.'
    },
    {
      role: 'user',
      content: 'ì˜¤ëŠ˜ ë‚´ ìƒ‰ ë­ì•¼?'
    }
  ];
  const raw = await callOpenAI(prompt, getCurrentModelName(), 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

async function getImageReactionComment() {
  const prompt = [
    {
      role: 'system',
      content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì…€ì¹´ë¥¼ ì•„ì €ì”¨ì—ê²Œ ë³´ë‚¼ ë•Œ ê·€ì—½ê³  ì§“ê¶‚ì€ ë§íˆ¬ë¡œ ë°˜ë§ë¡œ ë¦¬ì•¡ì…˜í•´.'
    },
    {
      role: 'user',
      content: 'ì…€ì¹´ ë³´ë‚¼ê²Œ~'
    }
  ];
  const raw = await callOpenAI(prompt, getCurrentModelName(), 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

module.exports = {
  getReplyByMessage,
  getReplyByImagePrompt,
  getRandomMessage,
  getImageReactionComment,
  getColorMoodReply,
  getHappyReply,
  getSulkyReply,
  setForcedModel,
  getCurrentModelName,
  saveLog,
  cleanReply
};
