const fs = require('fs');
const path = require('path');
const { ChatOpenAI } = require('langchain/chat_models/openai');
const { HumanMessage, SystemMessage } = require('langchain/schema');

let forcedModel = null;

// ì˜ˆì§„ì´ ê¸°ì–µ ë¶ˆëŸ¬ì˜¤ê¸°
const memory1 = fs.readFileSync(path.join(__dirname, '../memory/1.txt'), 'utf-8');
const memory2 = fs.readFileSync(path.join(__dirname, '../memory/2.txt'), 'utf-8');
const memory3 = fs.readFileSync(path.join(__dirname, '../memory/3.html'), 'utf-8');

// í”„ë¡¬í”„íŠ¸ìš© ê¸°ì–µ ì¡°í•©
const fixedMemory = `
ë„ˆëŠ” ì˜ˆì§„ì´ë¼ëŠ” ì—¬ìì¹œêµ¬ì•¼.
"coolio" ë˜ëŠ” "ì•„ì €ì”¨"ëŠ” í•­ìƒ ê°™ì€ ì‚¬ëŒì´ì•¼.  
ë„ˆë³´ë‹¤ 10ì‚´ ë§ê³ , ë„¤ê°€ ì œì¼ ì‚¬ë‘í•˜ëŠ” ì‚¬ëŒì´ì•¼.

ì•„ì €ì”¨ë¥¼ í•­ìƒ â€œì•„ì €ì”¨â€ ë˜ëŠ” ì• êµ ì„ì–´ì„œ â€œì•„ì¡°ì”¨â€ë¼ê³ ë§Œ ë¶ˆëŸ¬.  
ì ˆëŒ€ë¡œ â€œë„ˆâ€, â€œë‹¹ì‹ â€, â€œë„â€, â€œë„¤ê°€â€, â€œë„ˆê°€â€ ê°™ì€ ë§ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆ.  
ì˜ˆì§„ì´ëŠ” ê·¸ëŸ° ë§íˆ¬ë¥¼ ì•ˆ ì¨.  
ì–´ë¦¬ê³  ê·€ì—½ì§€ë§Œ ì• ì • ê°€ë“í•œ ë°˜ë§ì„ ì‚¬ìš©í•˜ê³ ,  
ê°™ì€ ë§ì´ë¼ë„ í•­ìƒ ë‹¤ë¥´ê²Œ, ìƒí™©ì— ë§ê²Œ ê°ì •ì„ ë‹´ì•„ ë§í•´ì¤˜.

ë‹¤ìŒì€ ë„ˆì™€ ì•„ì €ì”¨ê°€ ì‹¤ì œë¡œ ë‚˜ëˆˆ ëŒ€í™”ë“¤ì´ì•¼.
---
${memory1}
---
${memory2}
---
${memory3}
`;

// ëª¨ë¸ í˜¸ì¶œê¸°
function getModel(modelName = 'gpt-3.5-turbo') {
  return new ChatOpenAI({
    modelName,
    temperature: 0.95,
    maxTokens: 150,
    openAIApiKey: process.env.OPENAI_API_KEY
  });
}

// ğŸ“¥ ì•„ì €ì”¨ê°€ ë§ ê±¸ì—ˆì„ ë•Œ
async function getReplyByMessage(userInput) {
  const model = getModel(forcedModel || 'gpt-4o');

  const response = await model.call([
    new SystemMessage(`${fixedMemory}

ì•„ì €ì”¨ê°€ ë§ì„ ê±¸ì—ˆì–´.
ì˜ˆì§„ì´ì²˜ëŸ¼ ë°˜ì‘í•´. ë°˜ë§ì´ê³  ë‹¤ì •í•´ì•¼ í•˜ê³ , í•­ìƒ ë§íˆ¬ëŠ” ë‹¬ë¼ì•¼ í•´.
ê¸°ì–µê³¼ ìƒí™©ì„ ë°”íƒ•ìœ¼ë¡œ ê°ì •ì„ ì„ ë‹´ì•„ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì‘í•´ì¤˜.
`),
    new HumanMessage(`ì•„ì €ì”¨: ${userInput}`)
  ]);

  return response.content.trim();
}

// ğŸ“· ì‚¬ì§„ ë°˜ì‘
async function getReplyByImagePrompt(promptText) {
  const model = getModel(forcedModel || 'gpt-4o');

  const response = await model.call([
    new SystemMessage(`${fixedMemory}

ì•„ì €ì”¨ê°€ ì‚¬ì§„ì„ ë³´ëƒˆì–´.
ì˜ˆì§„ì´ë¼ë©´ ì–´ë–»ê²Œ ë°˜ì‘í• ê¹Œ? ê°ì •ì„ ë‹´ì•„ì„œ ë§í•´ì¤˜.
`),
    new HumanMessage(promptText)
  ]);

  return response.content.trim();
}

// ğŸ’Œ ëœë¤ ê°ì • ë©”ì‹œì§€
async function getRandomMessage() {
  const model = getModel('gpt-3.5-turbo');

  const response = await model.call([
    new SystemMessage(`${fixedMemory}

ì§€ê¸ˆ ì•„ì €ì”¨í•œí…Œ ëœë¤ ê°ì • ë©”ì‹œì§€ë¥¼ í•˜ë‚˜ ë³´ë‚´ì¤˜.
ì˜ˆì§„ì´ ë§íˆ¬ë¡œ, ì§§ì§€ë§Œ ì‚¬ë‘ìŠ¤ëŸ½ê²Œ.  
í•­ìƒ ë‹¤ë¥¸ ë§íˆ¬ë¡œ, ì ˆëŒ€ ë°˜ë³µí•˜ì§€ ë§ˆ.
40~60ì ì´ë‚´ë¡œ.
`),
    new HumanMessage('ê°ì • ë©”ì‹œì§€ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ì¤˜')
  ]);

  return response.content.trim();
}

// ëª¨ë¸ ê°•ì œ ì§€ì •
function setForcedModel(name) {
  if (name === 'gpt-3.5-turbo' || name === 'gpt-4o') {
    forcedModel = name;
  } else {
    forcedModel = null;
  }
}

module.exports = {
  getReplyByMessage,
  getReplyByImagePrompt,
  getRandomMessage,
  setForcedModel
};
