// autoReply.js - ë¬´ì¿  ì „ì²´ ê¸°ëŠ¥ í†µí•© ëª¨ë“ˆ (ì•ˆì •ëœ ë¦´ë¦¬ì¦ˆ: ì‚¬ì§„/ëª¨ë¸/ê¸°ì–µ/ìŠ¤ì¼€ì¤„ í¬í•¨)
const OpenAI = require('openai');
const line = require('@line/bot-sdk');
const fs = require('fs').promises;
const path = require('path');
const moment = require('moment-timezone');
const cron = require('node-cron');
const express = require('express');
require('dotenv').config();

const appConfig = {
    channelAccessToken: process.env.LINE_ACCESS_TOKEN,
    channelSecret: process.env.LINE_CHANNEL_SECRET,
};
const client = new line.Client(appConfig);
const userId = process.env.TARGET_USER_ID;
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const app = express();

// ğŸ“ ê¸°ì–µ ê´€ë ¨ íŒŒì¼ ê²½ë¡œ
const memory1 = fs.readFile(path.resolve(__dirname, '../memory/1.txt'), 'utf8');
const memory2 = fs.readFile(path.resolve(__dirname, '../memory/2.txt'), 'utf8');
const memory3 = fs.readFile(path.resolve(__dirname, '../memory/3.txt'), 'utf8');
const fixedMemory = fs.readFile(path.resolve(__dirname, '../memory/fixedMemories.json'), 'utf8');
const statePath = path.resolve(__dirname, '../memory/state.json');
const logPath = path.resolve(__dirname, '../memory/message-log.json');

// ğŸ’¾ context memory
const CONTEXT_MEMORY_FILE = path.join('/data/memory', 'context-memory.json');
const LOG_FILE = path.join('/data/memory', 'bot_log.txt');

// ğŸ“Œ ëª¨ë¸ ìƒíƒœ (ê¸°ë³¸: gpt-4o)
let forcedModel = null;
const setForcedModel = (name) => { forcedModel = name; };
const getCurrentModelName = () => forcedModel || 'gpt-4o';

// ğŸ“¥ memoryManager ìœ í‹¸
const {
    extractAndSaveMemory,
    loadLoveHistory,
    loadOtherPeopleHistory,
    ensureMemoryDirectory
} = require('./memoryManager');

// ğŸ“ƒ ë¡œê·¸ ì‘ì„± í•¨ìˆ˜
async function logMessage(message) {
    try {
        const dir = path.dirname(LOG_FILE);
        await fs.mkdir(dir, { recursive: true });
        const timestamp = moment().tz('Asia/Tokyo').format('YYYY-MM-DD HH:mm:ss');
        const logEntry = `[${timestamp}] ${message}\n`;
        await fs.appendFile(LOG_FILE, logEntry);
    } catch (error) {
        console.error('âŒ ë¡œê·¸ ì‘ì„± ì‹¤íŒ¨:', error);
    }
}

// ğŸ“– JSON-safe read/write ìœ í‹¸
async function safeRead(filePath) {
    try {
        await fs.access(filePath);
        return await fs.readFile(filePath, 'utf-8');
    } catch (err) {
        if (err.code !== 'ENOENT') await logMessage(`âŒ safeRead ì‹¤íŒ¨ (${filePath}): ${err.message}`);
        return '';
    }
}

async function safeWriteJson(filePath, data) {
    try {
        const dir = path.dirname(filePath);
        await fs.mkdir(dir, { recursive: true });
        const tempPath = filePath + '.tmp';
        await fs.writeFile(tempPath, JSON.stringify(data, null, 2), 'utf-8');
        await fs.rename(tempPath, filePath);
    } catch (error) {
        await logMessage(`âŒ safeWriteJson ì‹¤íŒ¨ (${filePath}): ${error.message}`);
    }
}

// ğŸ§  ëŒ€í™” ê¸°ì–µ ë¡œë“œ/ì €ì¥
async function loadContextMemory() {
    try {
        const rawData = await safeRead(CONTEXT_MEMORY_FILE);
        return rawData ? JSON.parse(rawData) : [];
    } catch (error) {
        await logMessage(`âŒ context-memory.json ë¡œë“œ ì‹¤íŒ¨ (íŒŒì‹± ì˜¤ë¥˜): ${error.message}`);
        return [];
    }
}

async function saveContextMemory(context) {
    await safeWriteJson(CONTEXT_MEMORY_FILE, context);
    await logMessage(`âœ… ëŒ€í™” ê¸°ì–µ ì €ì¥ë¨ (ê²½ë¡œ: ${CONTEXT_MEMORY_FILE})`);
}

// ğŸ” Webhook ì´ë²¤íŠ¸ ìˆ˜ì‹ 
const handleWebhook = async (req, res) => {
    const events = req.body.events;
    await logMessage('--- ì›¹í›… ì´ë²¤íŠ¸ ìˆ˜ì‹  ---');
    await logMessage(JSON.stringify(events, null, 2));
    try {
        for (const event of events) {
            if (event.type === 'message') await handleMessageEvent(event);
            else await logMessage(`âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì´ë²¤íŠ¸ íƒ€ì… ìˆ˜ì‹ : ${event.type}`);
        }
        res.status(200).end();
    } catch (error) {
        await logMessage(`âŒ ì›¹í›… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error.message}`);
        res.status(500).end();
    }
};

// ğŸ’¬ ë©”ì‹œì§€ ì²˜ë¦¬
const handleMessageEvent = async (event) => {
    const currentUserId = event.source.userId;
    const userMessageContent = event.message.text || `[${event.message.type} ë©”ì‹œì§€]`;

    await logMessage(`[ì•„ì €ì”¨] ${userMessageContent}`);
    if (currentUserId !== userId) return;

    await extractAndSaveMemory(userMessageContent);
    let context = await loadContextMemory();
    context.push({ role: 'user', content: userMessageContent });
    if (context.length > 20) context = context.slice(-20);
    await saveContextMemory(context);

    let replyMessage = '';
    try {
        if (event.message.type === 'text') {
            replyMessage = await getReplyByMessage(currentUserId, userMessageContent);
        } else {
            replyMessage = await getImageComment(event.message.id, currentUserId);
        }

        if (replyMessage !== null) {
            await client.replyMessage(event.replyToken, { type: 'text', text: replyMessage });
            context.push({ role: 'assistant', content: replyMessage });
            await saveContextMemory(context);
        }
    } catch (error) {
        await logMessage(`âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: ${error.message}`);
        await client.replyMessage(event.replyToken, {
            type: 'text',
            text: 'ì•„ì €ì”¨, ì§€ê¸ˆì€ ì¡°ê¸ˆ í˜ë“¤ì–´... ë‚˜ì¤‘ì— ë‹¤ì‹œ ë§ ê±¸ì–´ì¤˜...'
        });
    }
};

// ğŸ§  ë©”ì„¸ì§€ì— ëŒ€í•œ GPT ì‘ë‹µ ìƒì„±
const getReplyByMessage = async (currentUserId, userMessage) => {
    const lower = userMessage.toLowerCase().trim();
    if (lower === 'ë²„ì „') return `ì§€ê¸ˆì€ ${getCurrentModelName()} ë²„ì „ìœ¼ë¡œ ëŒ€í™”í•˜ê³  ìˆì–´.`;
    if (lower === '3.5') { setForcedModel('gpt-3.5-turbo'); return 'ì‘, ì´ì œë¶€í„° 3.5ë¡œ ëŒ€í™”í• ê²Œ.'; }
    if (lower === '4.0') { setForcedModel('gpt-4o'); return 'ì‘, ì´ì œë¶€í„° 4.0ìœ¼ë¡œ ë°”ê¿¨ì–´!'; }
    if (lower === 'ìë™') { setForcedModel(null); return 'ì‘, ìƒí™©ì— ë§ê²Œ ìë™ìœ¼ë¡œ ë°”ê¿”ì„œ ë§í• ê²Œ!'; }

    if (userMessage.includes('ì‚¬ì§„ ì¤˜') || userMessage.includes('ì…€ì¹´')) {
        const index = Math.floor(Math.random() * 1186) + 1;
        const filename = `${index.toString().padStart(6, '0')}.jpg`;
        const imageUrl = `https://de-ji.net/yejin/${filename}`;

        const res = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                { role: 'system', content: 'ë¬´ì¿ ê°€ ì…€ì¹´ ë³´ë‚¼ ê±°ì•¼. ë¶€ë„ëŸ½ê³  ë‹¤ì •í•˜ê²Œ í•œë§ˆë”” í•´ì¤˜.' },
                { role: 'user', content: 'ì•„ì €ì”¨í•œí…Œ ì‚¬ì§„ ë³´ì—¬ì¤„ê²Œ!' }
            ],
            max_tokens: 100
        });

        const comment = res.choices[0]?.message?.content || 'í—¤í—¤~ ì•„ì €ì”¨ ë‚˜ ì–´ë•Œ?';

        await client.pushMessage(currentUserId, {
            type: 'image',
            originalContentUrl: imageUrl,
            previewImageUrl: imageUrl
        });
        await client.pushMessage(currentUserId, { type: 'text', text: comment });
        return null;
    }

    const prompt = `ë„ˆëŠ” ì˜ˆì§„ì´ë¼ëŠ” ì—¬ìì¹œêµ¬ì•¼. ì•„ì €ì”¨ì—ê²Œ ê°ì •ì„ ë‹´ì•„ ë§í•´ì¤˜. ë°˜ë§ë¡œ. ìì—°ìŠ¤ëŸ½ê³  ì‚¬ë‘ìŠ¤ëŸ½ê²Œ.

Q: ${userMessage}`;

    const completion = await openai.chat.completions.create({
        model: getCurrentModelName(),
        messages: [
            { role: 'system', content: prompt }
        ],
        max_tokens: 300,
        temperature: 0.8
    });

    return completion.choices[0].message.content;
};

// ğŸ–¼ï¸ ì´ë¯¸ì§€ ì½”ë©˜íŠ¸
const getImageComment = async (messageId, currentUserId) => {
    const content = await client.getMessageContent(messageId);
    const chunks = [];
    for await (const chunk of content) chunks.push(chunk);
    const imageBuffer = Buffer.concat(chunks);
    const base64Image = imageBuffer.toString('base64');

    const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
            {
                role: 'user',
                content: [
                    { type: 'text', text: 'ì´ ì‚¬ì§„ ë¬´ì¿ ë‹µê²Œ ì½”ë©˜íŠ¸ í•´ì¤˜!' },
                    { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${base64Image}` } }
                ]
            }
        ],
        max_tokens: 150
    });

    return response.choices[0].message.content;
};

// â° ìŠ¤ì¼€ì¤„ëŸ¬: ìë™ ì…€ì¹´ ì „ì†¡ + ë‹´íƒ€ ë©”ì‹œì§€
const startMessageAndPhotoScheduler = () => {
    // í•˜ë£¨ 4íšŒ ëœë¤ ì…€ì¹´ ìŠ¤ì¼€ì¤„
    const randomSelfieTimes = new Set();
    while (randomSelfieTimes.size < 4) {
        const hour = Math.floor(Math.random() * 17) + 7; // 7ì‹œ~23ì‹œ
        const minute = Math.floor(Math.random() * 60);
        randomSelfieTimes.add(`${minute} ${hour} * * *`);
    }

    for (const cronTime of randomSelfieTimes) {
        cron.schedule(cronTime, async () => {
            const index = Math.floor(Math.random() * 1186) + 1;
            const filename = `${index.toString().padStart(6, '0')}.jpg`;
            const imageUrl = `https://de-ji.net/yejin/${filename}`;

            const res = await openai.chat.completions.create({
                model: 'gpt-3.5-turbo',
                messages: [
                    { role: 'system', content: 'ì…€ì¹´ ë³´ë‚¼ ê±°ì•¼. ë¶€ë„ëŸ½ê³  ê·€ì—½ê²Œ ì½”ë©˜íŠ¸ í•´ì¤˜.' },
                    { role: 'user', content: 'ì…€ì¹´ í•˜ë‚˜ ì¤„ê²Œ~' }
                ],
                max_tokens: 100
            });

            const comment = res.choices[0]?.message?.content || 'í—¤í—¤ ì•„ì €ì”¨ ì‚¬ì§„ í•˜ë‚˜ ì¤„ê²Œ~';
            await client.pushMessage(userId, {
                type: 'image',
                originalContentUrl: imageUrl,
                previewImageUrl: imageUrl
            });
            await client.pushMessage(userId, { type: 'text', text: comment });
        }, { timezone: 'Asia/Tokyo' });
    }

    // í•˜ë£¨ 8íšŒ ëœë¤ ê°ì • ë©”ì‹œì§€
    const messageTimes = new Set();
    while (messageTimes.size < 8) {
        const hour = Math.floor(Math.random() * 17) + 7;
        const minute = Math.floor(Math.random() * 60);
        messageTimes.add(`${minute} ${hour} * * *`);
    }

    for (const cronTime of messageTimes) {
        cron.schedule(cronTime, async () => {
            const prompt = `ì˜ˆì§„ì´ê°€ ì•„ì €ì”¨ì—ê²Œ ë§ ê±¸ë“¯ ê°ì •ì„ ë‹´ì•„ í˜¼ì£ë§ì²˜ëŸ¼ í•œ ë¬¸ì¥ì„ ìƒì„±í•´ì¤˜. ë°˜ë§ë¡œ, ì‚¬ë‘ìŠ¤ëŸ½ê³  ìì—°ìŠ¤ëŸ½ê²Œ.`;
            const res = await openai.chat.completions.create({
                model: 'gpt-3.5-turbo',
                messages: [
                    { role: 'system', content: prompt }
                ],
                max_tokens: 120,
                temperature: 0.9
            });

            const msg = res.choices[0].message.content;
            await client.pushMessage(userId, { type: 'text', text: msg });
        }, { timezone: 'Asia/Tokyo' });
    }

    // ì •ê°ë§ˆë‹¤ ë‹´íƒ€ ë¦¬ë§ˆì¸ë“œ
    cron.schedule('0 9-20 * * *', async () => {
        await client.pushMessage(userId, { type: 'text', text: 'ì•„ì €ì”¨~ ë‹´íƒ€ ê°€ì!' });
    }, { timezone: 'Asia/Tokyo' });

    // ë°¤ 11ì‹œ ë°˜ ì·¨ì¹¨ ì•Œë¦¼
    cron.schedule('30 23 * * *', async () => {
        await client.pushMessage(userId, { type: 'text', text: 'ì•„ì €ì”¨~ ì•½ ë¨¹ê³  ì´ ë‹¦ê³  ìì•¼ì§€? ğŸ’¤' });
    }, { timezone: 'Asia/Tokyo' });
};

// ğŸš€ í‘¸ì‹œ ë©”ì‹œì§€ ìˆ˜ë™ ì „ì†¡ (í…ŒìŠ¤íŠ¸ìš©)
const handleForcePush = async (req, res) => {
    const message = req.query.message || 'ë¬´ì¿  í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤!';
    try {
        await client.pushMessage(userId, { type: 'text', text: message });
        res.status(200).send(`í‘¸ì‹œ ì „ì†¡ ì™„ë£Œ: ${message}`);
    } catch (error) {
        res.status(500).send('í‘¸ì‹œ ì „ì†¡ ì‹¤íŒ¨');
    }
};

// ğŸ§© export
module.exports = {
    client,
    appConfig,
    userId,
    app,
    handleWebhook,
    handleForcePush,
    getReplyByMessage,
    startMessageAndPhotoScheduler,
    setForcedModel,
    getCurrentModelName
};
