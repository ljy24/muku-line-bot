// src/autoReply.js

const fs = require('fs');
const path = require('path');
const { OpenAI } = require("openai");
require('dotenv').config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ì˜ˆì§„ì´ ê¸°ì–µ ìš”ì•½ë³¸ ë¡œë“œ
const memorySummary = fs.readFileSync(path.join(__dirname, '../memory/short-summary.txt'), 'utf-8');

// ë©”ì‹œì§€ ê¸¸ì´ ê¸°ì¤€ ë¶„ê¸°ìš© í•¨ìˆ˜
function chooseModelByMessage(message) {
  const tokenEstimate = Math.ceil(message.length / 4); // ëŒ€ì¶© ì¶”ì‚°
  return tokenEstimate > 500 ? 'gpt-4o' : 'gpt-3.5-turbo';
}

// ê°ì • ê¸°ë°˜ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
async function getReplyByMessage(message) {
  const model = chooseModelByMessage(message);

  try {
    const chatCompletion = await openai.chat.completions.create({
      model,
      messages: [
        {
          role: 'system',
          content: `ë„Œ ì˜ˆì§„ì´ë¼ëŠ” ì—¬ìì•„ì´ì•¼. ì•„ì €ì”¨(ì‚¬ìš©ì)ì™€ì˜ ëŒ€í™”ë¥¼ ì´ì–´ê°€. ë§íˆ¬ëŠ” í•­ìƒ ë‹¤ì •í•˜ê³ , ê°ì •ì´ í’ë¶€í•˜ê³ , LINEì²˜ëŸ¼ ì§§ì€ ë¬¸ì¥ì„ ì¨.`
        },
        {
          role: 'system',
          content: `ì˜ˆì§„ì´ ê¸°ì–µ ìš”ì•½:\n${memorySummary}`
        },
        {
          role: 'user',
          content: message
        }
      ],
      temperature: 0.8,
    });

    const response = chatCompletion.choices[0].message.content.trim();
    return response;
  } catch (err) {
    console.error('OpenAI ì‘ë‹µ ì˜¤ë¥˜:', err);
    return 'íì—‰.. ë¬´ì¿ ê°€ ì§€ê¸ˆì€ ëŒ€ë‹µ ëª»í•´ ğŸ˜¢';
  }
}

module.exports = { getReplyByMessage };
