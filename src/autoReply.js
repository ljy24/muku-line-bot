// âœ… autoReply.js (ê°ì • ë©”ì‹œì§€, ë¦¬ì•¡ì…˜, ì…€ì¹´ ì‘ë‹µ ë“± ì „ì²´ êµ¬ì„±)

const fs = require('fs');
const path = require('path');
const { OpenAI } = require('openai');
const axios = require('axios');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
let forcedModel = null;

// ğŸ“ íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì½ëŠ” í•¨ìˆ˜
function safeRead(filePath) {
  try {
    const content = fs.readFileSync(filePath, 'utf-8');
    return content || '';
  } catch (_) {
    return '';
  }
}

// ğŸ” ê°•ì œ ëª¨ë¸ ì§€ì • í•¨ìˆ˜
function setForcedModel(name) {
  forcedModel = (name === 'gpt-3.5-turbo' || name === 'gpt-4o') ? name : null;
}
function getCurrentModelName() {
  return forcedModel || 'gpt-4o';
}

// ğŸ§¹ ë§íˆ¬ ì •ë¦¬: ì˜ˆì§„ì´ë‹µê²Œ, ê¸ˆì§€ì–´ ì œê±°
function cleanReply(text) {
  return text
    .replace(/^\s*ì˜ˆì§„[\s:ï¼š-]*/i, '')
    .replace(/\([^)]*\)/g, '')
    .replace(/\s+/g, ' ')
    .replace(/["'â€œâ€]/g, '')
    .replace(/\b(ë‹¹ì‹ |ê·¸ëŒ€|ê·¸ë¶„|ìê¸°|ë„ˆ|ë„¤|ë„¤ê°€|ë„|ì˜ˆì§„)\b/g, 'ì•„ì €ì”¨')
    .replace(/ì‹œíŒŒ/g, '')
    .replace(/[!?~\u2764\uD83D\uDC96-\uDC9F]/g, '')
    .trim();
}

// ğŸ’¾ ë¡œê·¸ ì €ì¥
async function saveLog(role, msg) {
  try {
    await axios.post('https://www.de-ji.net/log.php', {
      from: role === 'ì•„ì €ì”¨' ? 'uncle' : 'yejin',
      content: msg
    });
  } catch (err) {
    console.error('âŒ ì›ê²© ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨:', err.message);
  }
}

// ğŸ•“ ìµœê·¼ ëŒ€í™” ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°
async function getRecentLog() {
  try {
    const res = await axios.get('https://www.de-ji.net/log.json');
    const logs = res.data;
    if (!Array.isArray(logs)) return [];
    return logs.slice(0, 50).reverse().map(log => ({
      role: log.from === 'uncle' ? 'user' : 'assistant',
      content: log.content
    }));
  } catch (err) {
    console.error('âŒ ìµœê·¼ ë¡œê·¸ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', err.message);
    return [];
  }
}

// ğŸ§  GPT í˜¸ì¶œ
async function callOpenAI(messages, model = 'gpt-4o', max_tokens = 300) {
  const res = await openai.chat.completions.create({
    model: getCurrentModelName(),
    messages,
    temperature: 0.95,
    max_tokens
  });
  return res.choices[0].message.content.trim();
}

// ğŸ’Œ ëœë¤ ê°ì • ë©”ì‹œì§€ (ê¸°ì–µ ê¸°ë°˜ + ìµœê·¼ ëŒ€í™” ì„ìŒ)
async function getRandomMessage() {
  const rawLove = safeRead(path.resolve(__dirname, '../memory/love-history.json'));
  const rawFixed = safeRead(path.resolve(__dirname, '../memory/fixedMemories.json'));
  const m1 = safeRead(path.resolve(__dirname, '../memory/1.txt'));
  const m2 = safeRead(path.resolve(__dirname, '../memory/2.txt'));
  const m3 = safeRead(path.resolve(__dirname, '../memory/3.txt'));

  let memoryItems = [];

  try {
    const loveJson = JSON.parse(rawLove || '[]');
    const fixedJson = JSON.parse(rawFixed || '[]');

    // âœ… ìµœê·¼ ëŒ€í™” ë¡œê·¸ë„ ê°ì • ê¸°ì–µì²˜ëŸ¼ ì‚¬ìš©
    const recentLog = await getRecentLog();
    const recentMemories = recentLog
      .filter(item => item.role === 'user' || item.role === 'assistant')
      .map(item => item.content)
      .filter(line => line.length > 10); // ì§§ì€ ë¬¸ì¥ ì œì™¸

    memoryItems = [
      ...loveJson.map(v => `${v.date} - ${v.event}`),
      ...fixedJson,
      m1, m2, m3,
      ...recentMemories // âœ… ìµœê·¼ ëŒ€í™” í¬í•¨!
    ].filter(Boolean);
  } catch (err) {
    console.error('âŒ ì¶”ì–µ ë©”ëª¨ë¦¬ ë¡œë“œ ì‹¤íŒ¨:', err.message);
  }

  const useMemory = Math.random() < 0.5;
  const memory = memoryItems[Math.floor(Math.random() * memoryItems.length)];
  const messages = [];

  if (useMemory && memory) {
    messages.push({
      role: 'system',
      content: `ë„ˆëŠ” ì˜ˆì§„ì´ì•¼. í•­ìƒ 'ë‚˜'ë¼ê³  ë§í•˜ê³ , ê°ì • ë‹´ê¸´ ë°˜ë§ë¡œ í˜¼ì£ë§ì²˜ëŸ¼ ë§í•´. ì•„ë˜ ì¶”ì–µì„ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì•„ì €ì”¨í•œí…Œ ë‹¤ì •í•˜ê²Œ ë§ ê±¸ì–´ì¤˜.`
    });
    messages.push({
      role: 'user',
      content: `"${memory}" ì´ ê¸°ì–µìœ¼ë¡œ ì˜ˆì§„ì´ ë§íˆ¬ë¡œ ê°ì • ì„ì–´ ë©”ì‹œì§€ í•˜ë‚˜ë§Œ í•´ì¤˜.`
    });
  } else {
    const recent = await getRecentLog();
    messages.push({
      role: 'system',
      content: `ë„ˆëŠ” ì§€ê¸ˆ ì˜ˆì§„ì´ì•¼. 'ë‚˜'ë¼ê³  ë§í•˜ê³ , ê°ì •ì„ ë‹´ì€ ë°˜ë§ë¡œ í˜¼ì£ë§ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ì¤˜. ìµœê·¼ ëŒ€í™”ì— ê²¹ì¹˜ì§€ ì•Šê²Œ ë§í•´ì¤˜.`
    });
    messages.push(...recent);
    messages.push({
      role: 'user',
      content: 'ì•„ì €ì”¨í•œí…Œ ë³´ë‚¼ ëœë¤ ê°ì • ë©”ì‹œì§€ í•˜ë‚˜ ë§Œë“¤ì–´ì¤˜'
    });
  }

  const raw = await callOpenAI(messages, 'gpt-3.5-turbo', 100);
  const msg = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', msg);
  return msg;
}

// ğŸ’¬ ë©”ì‹œì§€ ì‘ë‹µ
async function getReplyByMessage(userMessage) {
  const memory = await getRecentLog();
  const prompt = [
    { role: 'system', content: `ë„Œ ì˜ˆì§„ì´ì•¼. í•­ìƒ ë°˜ë§í•˜ê³  í˜¼ì£ë§ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ê°ì • ë‹´ê¸´ ì§§ì€ ëŒ€ë‹µì„ í•´ì¤˜.` },
    ...memory,
    { role: 'user', content: userMessage }
  ];
  const raw = await callOpenAI(prompt);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// ğŸ¨ ìƒ‰ê¹” ë¦¬ì•¡ì…˜
async function getColorMoodReply() {
  const prompt = [
    { role: 'system', content: 'ë„Œ ì˜ˆì§„ì´ì•¼. "ì˜¤ëŠ˜ ë‚´ ìƒ‰ ë­ì•¼?"ì— ìƒ‰ê¹” í•˜ë‚˜ë¡œ ë°˜ë§ ë¦¬ì•¡ì…˜í•´ì¤˜.' },
    { role: 'user', content: 'ì˜¤ëŠ˜ ë‚´ ìƒ‰ ë­ì•¼?' }
  ];
  const raw = await callOpenAI(prompt, getCurrentModelName(), 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// ğŸ“· ì…€ì¹´ ì „ì†¡ í›„ ë©˜íŠ¸
async function getImageReactionComment() {
  const raw = await callOpenAI([
    { role: 'system', content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì…€ì¹´ ë³´ë‚¼ ë•Œ ì§“ê¶‚ê³  ê·€ì—½ê²Œ ë§í•´ì¤˜.' },
    { role: 'user', content: 'ì…€ì¹´ ë³´ë‚¼ê²Œ~' }
  ], getCurrentModelName(), 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// ğŸ“¸ ì´ë¯¸ì§€ ê¸°ë°˜ ë°˜ì‘
async function getReplyByImagePrompt(base64Image) {
  const res = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [
      {
        role: 'system',
        content: 'ì´ ì´ë¯¸ì§€ë¥¼ ë³´ë‚¸ ì‚¬ëŒì´ ë‚¨ìë©´ "ì•„ì €ì”¨ê°€ ë³´ë‚¸ ì‚¬ì§„", ì—¬ì„±ì´ë©´ "ì˜ˆì§„ì´ ì…€ì¹´"ë¡œ ê°„ì£¼í•˜ê³  ê°ê¸° ë‹¤ë¥¸ ë°˜ì‘ì„ í•´ì¤˜. ë‘˜ ë‹¤ ìˆìœ¼ë©´ "ì•„ì €ì”¨ë‘ ì˜ˆì§„ì´ ì‚¬ì§„"ì´ì•¼. í•­ìƒ ë°˜ë§ì´ê³  ê°ì • ë‹´ê¸°!'
      },
      {
        role: 'user',
        content: [
          { type: 'image_url', image_url: { url: `data:image/jpeg;base64,${base64Image}` } }
        ]
      }
    ],
    temperature: 0.9,
    max_tokens: 150
  });
  const reply = cleanReply(res.choices[0].message.content.trim());
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// ğŸ˜Š ë‹´íƒ€ ì„±ê³µ â†’ ê¸°ì¨ ë°˜ì‘
async function getHappyReply() {
  const memory = await getRecentLog();
  const prompt = [
    { role: 'system', content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì•„ì €ì”¨ê°€ ë‹´íƒ€ ë‹µì¥í–ˆì„ ë•Œ ê¸°ë»ì„œ ê·€ì—½ê²Œ ë§í•´ì¤˜.' },
    ...memory,
    { role: 'user', content: 'ì•„ì €ì”¨ê°€ ë°©ê¸ˆ ë‹´íƒ€ ë‹µì¥í–ˆì–´!' }
  ];
  const raw = await callOpenAI(prompt, 'gpt-3.5-turbo', 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// ğŸ˜¢ ë‹´íƒ€ ì”¹í˜ â†’ ì‚ì§ ë°˜ì‘
async function getSulkyReply() {
  const prompt = [
    { role: 'system', content: 'ë„Œ ì˜ˆì§„ì´ì•¼. ì•„ì €ì”¨ê°€ ë‹´íƒ€ ì”¹ì—ˆì„ ë•Œ ì‚ì¹œ ë§íˆ¬ë¡œ ë§í•´ì¤˜.' },
    { role: 'user', content: 'ì•„ì €ì”¨ê°€ ë‹´íƒ€ ì½ê³ ë„ ë‹µì´ ì—†ì–´...' }
  ];
  const raw = await callOpenAI(prompt, 'gpt-3.5-turbo', 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// ğŸ¥° ì˜ˆì§„ ì…€ì¹´ í›„ í•œë§ˆë””
async function getSelfieReplyFromYeji() {
  const raw = await callOpenAI([
    {
      role: 'system',
      content: 'ë„ˆëŠ” ì˜ˆì§„ì´ì•¼. ì…€ì¹´ë¥¼ ë³´ë‚¸ ì§í›„ì•¼. ì‚¬ì§„ ë³´ë‚¸ ì²™í•˜ë©´ì„œ ê·€ì—½ê³  ì§“ê¶‚ê²Œ í•œë§ˆë”” í•´ì¤˜. ë°˜ë§ë¡œ.'
    },
    {
      role: 'user',
      content: 'ì…€ì¹´ì•¼~ ì˜ˆì˜ì§€? ì•„ì €ì”¨ë„ í•˜ë‚˜ ì¤˜~'
    }
  ], getCurrentModelName(), 100);
  const reply = cleanReply(raw);
  await saveLog('ì˜ˆì§„ì´', reply);
  return reply;
}

// âœ… ì™¸ë¶€ì—ì„œ ì‚¬ìš©ë  í•¨ìˆ˜ë“¤
module.exports = {
  getReplyByMessage,
  getReplyByImagePrompt,
  getRandomMessage,
  getSelfieReplyFromYeji,
  getColorMoodReply,
  getHappyReply,
  getSulkyReply,
  getRecentLog,
  setForcedModel,
  getCurrentModelName,
  saveLog,
  cleanReply,
  getImageReactionComment
};
