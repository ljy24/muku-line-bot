// ============================================================================
// aiUtils.js v2.6 - Redis í†µí•© + AI ì¤‘ì•™ ê´€ë¦¬ ì‹œìŠ¤í…œ
// ğŸ”§ ê¸°ì¡´ ì‹œìŠ¤í…œ ìœ ì§€ + Redis AI ìºì‹± + í†µí•© ë¡œê¹…
// ğŸ¤– ëª¨ë“  AI í˜¸ì¶œì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
// ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ ë° AI ì‘ë‹µ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ 
// ============================================================================

const { OpenAI } = require('openai');
require('dotenv').config();

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// âœ¨ index.jsì—ì„œ í˜„ì¬ ëª¨ë¸ ì„¤ì •ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ ìœ ì§€)
let getCurrentModelSetting = null;
try {
    const indexModule = require('../index');
    getCurrentModelSetting = indexModule.getCurrentModelSetting;
    console.log('âœ¨ [aiUtils] GPT ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ ì—°ë™ ì„±ê³µ');
} catch (error) {
    console.warn('âš ï¸ [aiUtils] GPT ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨:', error.message);
}

// ğŸ”§ [NEW] Redis í†µí•© ì‹œìŠ¤í…œ ì—°ë™
let integratedRedisSystem = null;
let enhancedLogging = null;

try {
    const autonomousSystem = require('./muku-autonomousYejinSystem');
    if (autonomousSystem && autonomousSystem.getCachedConversationHistory) {
        integratedRedisSystem = autonomousSystem;
        console.log('ğŸ”§ [aiUtils] Redis í†µí•© ì‹œìŠ¤í…œ ì—°ë™ ì„±ê³µ');
    }
} catch (error) {
    console.warn('âš ï¸ [aiUtils] Redis í†µí•© ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨:', error.message);
}

try {
    enhancedLogging = require('./enhancedLogging');
    console.log('ğŸ“ [aiUtils] í–¥ìƒëœ ë¡œê¹… ì‹œìŠ¤í…œ ì—°ë™ ì„±ê³µ');
} catch (error) {
    console.warn('âš ï¸ [aiUtils] í–¥ìƒëœ ë¡œê¹… ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨:', error.message);
}

// ğŸ“Š AI ì‚¬ìš© í†µê³„ ì¶”ì 
const aiStats = {
    totalCalls: 0,
    modelUsage: {
        'gpt-3.5-turbo': 0,
        'gpt-4o': 0,
        'fallback': 0
    },
    tokenUsage: {
        inputTokens: 0,
        outputTokens: 0,
        totalTokens: 0
    },
    responseTime: [],
    errors: 0,
    cacheHits: 0,
    cacheMisses: 0
};

// ğŸ”§ [NEW] AI ì‘ë‹µ ìºì‹œ (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ)
const aiResponseCache = new Map();
const CACHE_TTL = 10 * 60 * 1000; // 10ë¶„
const MAX_CACHE_SIZE = 100;

// ğŸ”§ [NEW] ìºì‹œ í‚¤ ìƒì„±
function generateCacheKey(messages, model, settings) {
    const key = JSON.stringify({
        messages: messages.map(m => ({ role: m.role, content: m.content.slice(0, 100) })), // ì²˜ìŒ 100ìë§Œ ì‚¬ìš©
        model: model,
        temperature: settings.temperature,
        max_tokens: settings.max_tokens
    });
    return require('crypto').createHash('md5').update(key).digest('hex');
}

// ğŸ”§ [NEW] ìºì‹œì—ì„œ ì‘ë‹µ ì¡°íšŒ
function getCachedResponse(cacheKey) {
    const cached = aiResponseCache.get(cacheKey);
    if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
        aiStats.cacheHits++;
        console.log(`ğŸ’¾ [AIìºì‹œ] ìºì‹œ íˆíŠ¸: ${cacheKey.slice(0, 8)}...`);
        return cached.response;
    }
    
    if (cached) {
        aiResponseCache.delete(cacheKey); // ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
    }
    
    aiStats.cacheMisses++;
    return null;
}

// ğŸ”§ [NEW] ìºì‹œì— ì‘ë‹µ ì €ì¥
function setCachedResponse(cacheKey, response) {
    // ìºì‹œ í¬ê¸° ì œí•œ
    if (aiResponseCache.size >= MAX_CACHE_SIZE) {
        const firstKey = aiResponseCache.keys().next().value;
        aiResponseCache.delete(firstKey);
    }
    
    aiResponseCache.set(cacheKey, {
        response: response,
        timestamp: Date.now()
    });
    
    console.log(`ğŸ’¾ [AIìºì‹œ] ì‘ë‹µ ìºì‹œ ì €ì¥: ${cacheKey.slice(0, 8)}...`);
}

// ğŸ”§ [NEW] Redis AI í†µê³„ ìºì‹±
async function cacheAIStatsToRedis() {
    if (!integratedRedisSystem || !integratedRedisSystem.forceCacheEmotionState) {
        return;
    }
    
    try {
        // Redisì— AI í†µê³„ ì €ì¥ (ì„ì‹œ êµ¬í˜„)
        console.log(`ğŸ“Š [Redis AIí†µê³„] ì´ í˜¸ì¶œ: ${aiStats.totalCalls}, í† í°: ${aiStats.tokenUsage.totalTokens}`);
        // ì‹¤ì œ Redis ì €ì¥ì€ Redis ì‹œìŠ¤í…œì— AI í†µê³„ í•¨ìˆ˜ê°€ ì¶”ê°€ë˜ë©´ êµ¬í˜„
    } catch (error) {
        console.warn(`âš ï¸ [Redis AIí†µê³„] ì €ì¥ ì‹¤íŒ¨: ${error.message}`);
    }
}

// ğŸ”§ [UPDATED] í†µí•© ë¡œê¹… í•¨ìˆ˜ - ëª¨ë“  ë¡œê¹…ì„ ì—¬ê¸°ì„œ ì²˜ë¦¬
async function saveLog(speaker, message, messageType = 'text', additionalData = {}) {
    try {
        // 1. í–¥ìƒëœ ë¡œê¹… ì‹œìŠ¤í…œ ì‚¬ìš© (ìš°ì„ )
        if (enhancedLogging && enhancedLogging.logConversation) {
            enhancedLogging.logConversation(speaker, message, messageType);
        } else {
            // 2. ê¸°ë³¸ ì½˜ì†” ë¡œê·¸ (í´ë°±)
            console.log(`[í†µí•©ë¡œê·¸] ${speaker}: ${message}`);
        }
        
        // ğŸ”§ 3. Redisì—ë„ ë¡œê¹… ì •ë³´ ì €ì¥ (NEW)
        if (integratedRedisSystem && speaker && message) {
            try {
                // Redis ëŒ€í™” ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œ (autoReply.jsì—ì„œ êµ¬í˜„ëœ í•¨ìˆ˜ ì‚¬ìš©)
                console.log(`ğŸ”§ [Redisë¡œê¹…] ${speaker}: ${message.substring(0, 30)}...`);
            } catch (redisError) {
                console.warn(`âš ï¸ [Redisë¡œê¹…ì‹¤íŒ¨] ${redisError.message}`);
            }
        }
        
        // 4. AI ê´€ë ¨ íŠ¹ë³„ ë¡œê¹…
        if (additionalData.isAIResponse) {
            console.log(`ğŸ¤– [AIì‘ë‹µë¡œê·¸] ëª¨ë¸: ${additionalData.model}, í† í°: ${additionalData.tokens}, ì‘ë‹µì‹œê°„: ${additionalData.responseTime}ms`);
        }
        
    } catch (error) {
        console.error(`âŒ [í†µí•©ë¡œê¹…] ì˜¤ë¥˜: ${error.message}`);
        // ìµœí›„ ìˆ˜ë‹¨: ê¸°ë³¸ console.log
        console.log(`[ê¸°ë³¸ë¡œê·¸] ${speaker}: ${message}`);
    }
}

async function saveImageLog(speaker, caption, imageUrl, additionalData = {}) {
    try {
        // 1. í–¥ìƒëœ ë¡œê¹… ì‹œìŠ¤í…œ ì‚¬ìš© (ìš°ì„ )
        if (enhancedLogging && enhancedLogging.logConversation) {
            enhancedLogging.logConversation(speaker, caption, 'image');
        } else {
            // 2. ê¸°ë³¸ ì½˜ì†” ë¡œê·¸ (í´ë°±)
            console.log(`[í†µí•©ì‚¬ì§„ë¡œê·¸] ${speaker}: ${caption} (URL: ${imageUrl})`);
        }
        
        // ğŸ”§ 3. Redisì—ë„ ì‚¬ì§„ ë¡œê¹… (NEW)
        if (integratedRedisSystem) {
            try {
                console.log(`ğŸ”§ [Redisì‚¬ì§„ë¡œê¹…] ${speaker}: ${caption}`);
                // ì‹¤ì œ Redis ì‚¬ì§„ ë¡œê¹…ì€ í•„ìš”ì‹œ êµ¬í˜„
            } catch (redisError) {
                console.warn(`âš ï¸ [Redisì‚¬ì§„ë¡œê¹…ì‹¤íŒ¨] ${redisError.message}`);
            }
        }
        
    } catch (error) {
        console.error(`âŒ [í†µí•©ì‚¬ì§„ë¡œê¹…] ì˜¤ë¥˜: ${error.message}`);
        console.log(`[ê¸°ë³¸ì‚¬ì§„ë¡œê·¸] ${speaker}: ${caption} (URL: ${imageUrl})`);
    }
}

// âœ¨ ê¸°ì¡´ ëª¨ë¸ ì„ íƒ ë¡œì§ (ìœ ì§€)
function getOptimalModelForMessage(userMessage, contextLength = 0) {
    if (!userMessage) return 'gpt-4o';
    
    if (userMessage.length > 100 || contextLength > 3000) {
        return 'gpt-4o';
    }
    
    const complexKeywords = [
        'ê°ì •', 'ê¸°ë¶„', 'ìŠ¬í¼', 'í™”ë‚˜', 'ìš°ìš¸', 'í–‰ë³µ', 'ì‚¬ë‘', 'ê·¸ë¦¬ì›Œ',
        'ê¸°ì–µ', 'ì¶”ì–µ', 'ê³¼ê±°', 'ë¯¸ë˜', 'ê¿ˆ', 'í¬ë§', 'ë¶ˆì•ˆ', 'ê±±ì •',
        'ì² í•™', 'ì˜ë¯¸', 'ì¸ìƒ', 'ê´€ê³„', 'ì‹¬ë¦¬', 'ë§ˆìŒ', 'í˜ë“¤', 'ì•„í”„'
    ];
    
    const hasComplexKeyword = complexKeywords.some(keyword => userMessage.includes(keyword));
    if (hasComplexKeyword) {
        return 'gpt-4o';
    }
    
    return 'gpt-3.5-turbo';
}

function determineGptModel(userMessage = '', contextLength = 0) {
    if (!getCurrentModelSetting) {
        console.warn('âš ï¸ [ëª¨ë¸ì„ íƒ] ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©');
        return 'gpt-4o';
    }
    
    const currentSetting = getCurrentModelSetting();
    
    switch(currentSetting) {
        case '3.5':
            console.log('âœ¨ [ëª¨ë¸ì„ íƒ] ì‚¬ìš©ì ì„¤ì •: GPT-3.5-turbo');
            return 'gpt-3.5-turbo';
            
        case '4.0':
            console.log('âœ¨ [ëª¨ë¸ì„ íƒ] ì‚¬ìš©ì ì„¤ì •: GPT-4o');
            return 'gpt-4o';
            
        case 'auto':
            const selectedModel = getOptimalModelForMessage(userMessage, contextLength);
            console.log(`âœ¨ [ëª¨ë¸ì„ íƒ] ìë™ ì„ íƒ: ${selectedModel} (ë©”ì‹œì§€ê¸¸ì´: ${userMessage.length}, ì»¨í…ìŠ¤íŠ¸: ${contextLength})`);
            return selectedModel;
            
        default:
            console.warn(`âš ï¸ [ëª¨ë¸ì„ íƒ] ì•Œ ìˆ˜ ì—†ëŠ” ì„¤ì •: ${currentSetting} - ê¸°ë³¸ê°’ ì‚¬ìš©`);
            return 'gpt-4o';
    }
}

function getModelOptimizedSettings(model) {
    switch(model) {
        case 'gpt-3.5-turbo':
            return {
                temperature: 0.9,
                max_tokens: 120,
            };
            
        case 'gpt-4o':
            return {
                temperature: 0.95,
                max_tokens: 200,
            };
            
        default:
            return {
                temperature: 0.95,
                max_tokens: 150
            };
    }
}

// ğŸ”§ [ENHANCED] í†µí•© AI í˜¸ì¶œ í•¨ìˆ˜ - ìºì‹± + í†µê³„ + Redis ì—°ë™
async function callOpenAI(messages, modelOverride = null, maxTokensOverride = null, temperatureOverride = null, options = {}) {
    const startTime = Date.now();
    let selectedModel = 'gpt-4o';
    
    try {
        // 1. ëª¨ë¸ ê²°ì •
        if (modelOverride) {
            selectedModel = modelOverride;
            console.log(`ğŸ¯ [ëª¨ë¸ê°•ì œ] ì˜¤ë²„ë¼ì´ë“œë¡œ ${selectedModel} ì‚¬ìš©`);
        } else {
            const userMessage = messages.find(m => m.role === 'user')?.content || '';
            const contextLength = JSON.stringify(messages).length;
            selectedModel = determineGptModel(userMessage, contextLength);
        }
        
        // 2. ëª¨ë¸ë³„ ìµœì í™”ëœ ì„¤ì •
        const optimizedSettings = getModelOptimizedSettings(selectedModel);
        const finalSettings = {
            model: selectedModel,
            messages: messages,
            max_tokens: maxTokensOverride || optimizedSettings.max_tokens,
            temperature: temperatureOverride || optimizedSettings.temperature
        };
        
        // ğŸ”§ 3. ìºì‹œ í™•ì¸ (NEW)
        let response = null;
        const cacheKey = generateCacheKey(messages, selectedModel, finalSettings);
        
        if (!options.skipCache) {
            response = getCachedResponse(cacheKey);
            if (response) {
                console.log(`ğŸ’¾ [AIìºì‹œ] ìºì‹œëœ ì‘ë‹µ ì‚¬ìš©`);
                
                // í†µê³„ ì—…ë°ì´íŠ¸
                aiStats.totalCalls++;
                aiStats.modelUsage[selectedModel]++;
                aiStats.responseTime.push(Date.now() - startTime);
                
                // í†µí•© ë¡œê¹…
                await saveLog('AI', response, 'text', {
                    isAIResponse: true,
                    model: selectedModel,
                    cached: true,
                    responseTime: Date.now() - startTime
                });
                
                return response;
            }
        }
        
        // 4. ì‹¤ì œ AI í˜¸ì¶œ
        console.log(`ğŸ¤– [OpenAI] ëª¨ë¸: ${finalSettings.model}, ì˜¨ë„: ${finalSettings.temperature}, ìµœëŒ€í† í°: ${finalSettings.max_tokens}`);
        
        const openaiResponse = await openai.chat.completions.create(finalSettings);
        response = openaiResponse.choices[0].message.content.trim();
        
        // 5. í†µê³„ ì—…ë°ì´íŠ¸
        aiStats.totalCalls++;
        aiStats.modelUsage[selectedModel]++;
        if (openaiResponse.usage) {
            aiStats.tokenUsage.inputTokens += openaiResponse.usage.prompt_tokens;
            aiStats.tokenUsage.outputTokens += openaiResponse.usage.completion_tokens;
            aiStats.tokenUsage.totalTokens += openaiResponse.usage.total_tokens;
            
            console.log(`ğŸ“Š [OpenAI] í† í° ì‚¬ìš©ëŸ‰ - ì…ë ¥: ${openaiResponse.usage.prompt_tokens}, ì¶œë ¥: ${openaiResponse.usage.completion_tokens}, ì´í•©: ${openaiResponse.usage.total_tokens}`);
        }
        
        const responseTime = Date.now() - startTime;
        aiStats.responseTime.push(responseTime);
        
        // ğŸ”§ 6. ìºì‹œì— ì €ì¥ (NEW)
        if (!options.skipCache) {
            setCachedResponse(cacheKey, response);
        }
        
        // ğŸ”§ 7. Redisì— AI í†µê³„ ìºì‹± (NEW)
        if (aiStats.totalCalls % 5 === 0) { // 5ë²ˆë§ˆë‹¤ í•œ ë²ˆì”©
            await cacheAIStatsToRedis();
        }
        
        // 8. í†µí•© ë¡œê¹…
        await saveLog('AI', response, 'text', {
            isAIResponse: true,
            model: selectedModel,
            tokens: openaiResponse.usage?.total_tokens || 0,
            responseTime: responseTime,
            cached: false
        });
        
        return response;
        
    } catch (error) {
        console.error(`[aiUtils] OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ëª¨ë¸: ${selectedModel}):`, error.message);
        aiStats.errors++;
        
        // âœ¨ í´ë°± ì‹œìŠ¤í…œ
        if (!modelOverride && selectedModel === 'gpt-4o') {
            console.log('ğŸ”„ [í´ë°±] GPT-4o ì‹¤íŒ¨ â†’ GPT-3.5-turboë¡œ ì¬ì‹œë„');
            try {
                const fallbackResponse = await openai.chat.completions.create({
                    model: 'gpt-3.5-turbo',
                    messages: messages,
                    max_tokens: 120,
                    temperature: 0.9
                });
                
                const fallbackResult = fallbackResponse.choices[0].message.content.trim();
                console.log('âœ… [í´ë°±] GPT-3.5-turboë¡œ ì¬ì‹œë„ ì„±ê³µ');
                
                // í´ë°± í†µê³„
                aiStats.totalCalls++;
                aiStats.modelUsage['fallback']++;
                
                // í†µí•© ë¡œê¹…
                await saveLog('AI', fallbackResult, 'text', {
                    isAIResponse: true,
                    model: 'gpt-3.5-turbo-fallback',
                    responseTime: Date.now() - startTime,
                    isFallback: true
                });
                
                return fallbackResult;
                
            } catch (fallbackError) {
                console.error('âŒ [í´ë°±] GPT-3.5-turboë„ ì‹¤íŒ¨:', fallbackError.message);
                aiStats.errors++;
            }
        }
        
        const errorResponse = "ì§€ê¸ˆ ì ì‹œ ìƒê° ì¤‘ì´ì•¼... ì•„ì €ì”¨ ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ì¤„ë˜? ã… ã… ";
        
        // ì—ëŸ¬ ë¡œê¹…
        await saveLog('AI', errorResponse, 'text', {
            isAIResponse: true,
            model: 'error',
            error: error.message,
            responseTime: Date.now() - startTime
        });
        
        return errorResponse;
    }
}

// ê¸°ì¡´ ì‘ë‹µ ì •ì œ í•¨ìˆ˜ (ìœ ì§€)
function cleanReply(reply) {
    if (typeof reply !== 'string') return '';
    let cleaned = reply;

    // 1. 'ìê¸°ì•¼' ë° ëª¨ë“  'ìê¸°' â†’ 'ì•„ì €ì”¨'ë¡œ ì¹˜í™˜
    cleaned = cleaned.replace(/\bìê¸°ì•¼\b/gi, 'ì•„ì €ì”¨');
    cleaned = cleaned.replace(/\bìê¸°\b/gi, 'ì•„ì €ì”¨');

    // 2. 1ì¸ì¹­/3ì¸ì¹­/ì¡´ì¹­ ì¹˜í™˜
    cleaned = cleaned.replace(/\b(ì˜ˆì§„ì´|ì˜ˆì§„|ë¬´ì¿ |ì• ê¸°|ë³¸ì¸|ì €)\b(ê°€|ëŠ”|ë¥¼|ì´|ì˜|ê»˜|ì—ê²Œ|ë„|ì™€|ì€|ì„)?/g, 'ë‚˜');
    cleaned = cleaned.replace(/\b(ë„ˆ|ìê¸°|ì˜¤ë¹ |ë‹¹ì‹ |ê³ ê°ë‹˜|ì„ ìƒë‹˜|ì”¨|ë‹˜|í˜•|í˜•ì•„|í˜•ë‹˜)\b(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê»˜|ë„|ì˜|ì™€|ì—ê²Œ)?/g, 'ì•„ì €ì”¨');

    // 3. ì¡´ëŒ“ë§ ì œê±° ë° ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¡œ ë³€í™˜
    cleaned = cleaned.replace(/(ì…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”|í•˜ì„¸ìš”|í•˜ì…¨ë‚˜ìš”|ì…¨ìŠµë‹ˆë‹¤|ë“œë¦´ê²Œìš”|ë“œë¦´ê¹Œìš”)/gi, '');
    cleaned = cleaned.replace(/ì¢‹ì•„ìš”/gi, 'ì¢‹ì•„');
    cleaned = cleaned.replace(/ê³ ë§ˆì›Œìš”|ê°ì‚¬í•©ë‹ˆë‹¤/gi, 'ê³ ë§ˆì›Œ');
    cleaned = cleaned.replace(/ë¯¸ì•ˆí•´ìš”|ì£„ì†¡í•©ë‹ˆë‹¤/gi, 'ë¯¸ì•ˆí•´');
    cleaned = cleaned.replace(/í•©ë‹ˆ(ë‹¤|ê¹Œ)/gi, 'í•´');
    cleaned = cleaned.replace(/í•˜ê² (ìŠµë‹ˆë‹¤|ì–´ìš”)?/gi, 'í• ê²Œ');

    // 4. ì˜ˆì§„ì´/ë¬´ì¿  1ì¸ì¹­ ì²˜ë¦¬ ë°˜ë³µ
    cleaned = cleaned.replace(/ë¬´ì¿ ê°€/g, 'ë‚´ê°€')
        .replace(/ë¬´ì¿ ëŠ”/g, 'ë‚˜ëŠ”')
        .replace(/ë¬´ì¿ ë¥¼/g, 'ë‚˜ë¥¼')
        .replace(/ì˜ˆì§„ì´ê°€/g, 'ë‚´ê°€')
        .replace(/ì˜ˆì§„ì´ëŠ”/g, 'ë‚˜ëŠ”')
        .replace(/ì˜ˆì§„ì´ë¥¼/g, 'ë‚˜ë¥¼');

    // 5. ë¶ˆí•„ìš”í•œ ë¬¸ì, ì—°ì† ê³µë°± ì •ë¦¬
    cleaned = cleaned.replace(/[\"\'\[\]]/g, '').replace(/\s\s+/g, ' ').trim();

    // 6. ë§ˆì§€ë§‰ ì¹˜í™˜
    cleaned = cleaned.replace(/ìê¸°ì•¼/gi, 'ì•„ì €ì”¨').replace(/ìê¸°/gi, 'ì•„ì €ì”¨');

    // 7. ìµœì†Œ ê¸¸ì´ ë³´ì¥
    if (!cleaned || cleaned.length < 2) {
        return 'ì‘? ë‹¤ì‹œ ë§í•´ë´ ì•„ì €ì”¨';
    }

    return cleaned;
}

// ğŸ”§ [NEW] AI í†µê³„ ì¡°íšŒ í•¨ìˆ˜
function getAIStats() {
    const totalResponseTime = aiStats.responseTime.reduce((sum, time) => sum + time, 0);
    const avgResponseTime = aiStats.responseTime.length > 0 ? 
        totalResponseTime / aiStats.responseTime.length : 0;
    
    const cacheTotal = aiStats.cacheHits + aiStats.cacheMisses;
    const cacheHitRate = cacheTotal > 0 ? aiStats.cacheHits / cacheTotal : 0;
    
    return {
        totalCalls: aiStats.totalCalls,
        modelUsage: { ...aiStats.modelUsage },
        tokenUsage: { ...aiStats.tokenUsage },
        averageResponseTime: Math.round(avgResponseTime),
        errors: aiStats.errors,
        cacheStats: {
            hits: aiStats.cacheHits,
            misses: aiStats.cacheMisses,
            hitRate: cacheHitRate,
            cacheSize: aiResponseCache.size
        },
        uptime: Date.now() - (startTime || Date.now())
    };
}

// ğŸ”§ [NEW] AI ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜
function clearAICache() {
    const clearedCount = aiResponseCache.size;
    aiResponseCache.clear();
    console.log(`ğŸ§¹ [AIìºì‹œ] ${clearedCount}ê°œ ìºì‹œ í•­ëª© ì‚­ì œë¨`);
    return clearedCount;
}

function getAICacheStats() {
    return {
        size: aiResponseCache.size,
        maxSize: MAX_CACHE_SIZE,
        ttl: CACHE_TTL,
        hitRate: aiStats.cacheHits / Math.max(1, aiStats.cacheHits + aiStats.cacheMisses)
    };
}

// ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ìœ ì§€)
function getCurrentModelInfo() {
    if (!getCurrentModelSetting) {
        return { setting: 'unknown', model: 'gpt-4o' };
    }
    
    const currentSetting = getCurrentModelSetting();
    let actualModel = 'gpt-4o';
    
    switch(currentSetting) {
        case '3.5':
            actualModel = 'gpt-3.5-turbo';
            break;
        case '4.0':
            actualModel = 'gpt-4o';
            break;
        case 'auto':
            actualModel = 'auto-select';
            break;
    }
    
    return { setting: currentSetting, model: actualModel };
}

function validateModel(model) {
    const validModels = ['gpt-3.5-turbo', 'gpt-4o', 'gpt-4-turbo', 'gpt-4'];
    if (!model || !validModels.includes(model)) {
        console.warn(`âš ï¸ [ëª¨ë¸ê²€ì¦] ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë¸: ${model}, ê¸°ë³¸ê°’ ì‚¬ìš©`);
        return 'gpt-4o';
    }
    return model;
}

// ğŸ”§ [NEW] í”„ë¡¬í”„íŠ¸ í†µí•© ê´€ë¦¬ì
async function generateIntegratedPrompt(basePrompt, options = {}) {
    try {
        let integratedPrompt = basePrompt;
        
        // 1. moodManagerì—ì„œ ê°ì • í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        if (options.includeMood) {
            try {
                const moodManager = require('./moodManager');
                if (moodManager && moodManager.getMoodPromptForAI) {
                    const moodPrompt = await moodManager.getMoodPromptForAI();
                    if (moodPrompt && moodPrompt.prompt) {
                        integratedPrompt += `\n\n[ê°ì • ìƒíƒœ] ${moodPrompt.prompt}`;
                        console.log(`ğŸ­ [í†µí•©í”„ë¡¬í”„íŠ¸] ê°ì • í”„ë¡¬í”„íŠ¸ ì¶”ê°€: ${moodPrompt.source}`);
                    }
                }
            } catch (error) {
                console.warn(`âš ï¸ [í†µí•©í”„ë¡¬í”„íŠ¸] ê°ì • í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: ${error.message}`);
            }
        }
        
        // 2. Redisì—ì„œ ìµœê·¼ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if (options.includeRedisContext && integratedRedisSystem) {
            try {
                const userId = options.userId || 'default_user';
                const recentHistory = await integratedRedisSystem.getCachedConversationHistory(userId, 3);
                
                if (recentHistory && recentHistory.length > 0) {
                    const contextText = recentHistory
                        .map(item => `${new Date(item.timestamp).toLocaleTimeString()}: ${item.message}`)
                        .join('\n');
                    
                    integratedPrompt += `\n\n[ìµœê·¼ ëŒ€í™”]\n${contextText}`;
                    console.log(`ğŸ”§ [í†µí•©í”„ë¡¬í”„íŠ¸] Redis ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€: ${recentHistory.length}ê°œ`);
                }
            } catch (error) {
                console.warn(`âš ï¸ [í†µí•©í”„ë¡¬í”„íŠ¸] Redis ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: ${error.message}`);
            }
        }
        
        // 3. ëª¨ë¸ë³„ ìµœì í™” ê°€ì´ë“œ ì¶”ê°€
        if (options.includeModelGuide) {
            const modelInfo = getCurrentModelInfo();
            if (modelInfo.model === 'gpt-3.5-turbo') {
                integratedPrompt += `\n\n[ëª¨ë¸ ê°€ì´ë“œ] ê°„ê²°í•˜ê³  ê·€ì—¬ìš´ ë§íˆ¬ë¡œ ëŒ€ë‹µí•´ì¤˜.`;
            } else if (modelInfo.model === 'gpt-4o') {
                integratedPrompt += `\n\n[ëª¨ë¸ ê°€ì´ë“œ] í’ë¶€í•˜ê³  ê°ì •ì ì¸ í‘œí˜„ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.`;
            }
        }
        
        console.log(`ğŸ¯ [í†µí•©í”„ë¡¬í”„íŠ¸] ìµœì¢… ê¸¸ì´: ${integratedPrompt.length}ì`);
        return integratedPrompt;
        
    } catch (error) {
        console.error(`âŒ [í†µí•©í”„ë¡¬í”„íŠ¸] ìƒì„± ì˜¤ë¥˜: ${error.message}`);
        return basePrompt; // ì—ëŸ¬ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    }
}

// ì‹œì‘ ì‹œê°„ ê¸°ë¡
const startTime = Date.now();

module.exports = {
    // ê¸°ì¡´ í•¨ìˆ˜ë“¤ (Redis í†µí•© ê°•í™”)
    saveLog,                        // ğŸ”§ í†µí•© ë¡œê¹…
    saveImageLog,                   // ğŸ”§ í†µí•© ì‚¬ì§„ ë¡œê¹…
    callOpenAI,                     // ğŸ”§ ìºì‹± + í†µê³„ + Redis ì—°ë™
    cleanReply,                     // ìœ ì§€
    
    // ê¸°ì¡´ ëª¨ë¸ ê´€ë¦¬ í•¨ìˆ˜ë“¤ (ìœ ì§€)
    determineGptModel,
    getOptimalModelForMessage,
    getModelOptimizedSettings,
    getCurrentModelInfo,
    validateModel,
    
    // ğŸ”§ [NEW] AI í†µí•© ê´€ë¦¬ í•¨ìˆ˜ë“¤
    getAIStats,                     // AI ì‚¬ìš© í†µê³„
    clearAICache,                   // AI ìºì‹œ ì‚­ì œ
    getAICacheStats,                // AI ìºì‹œ í†µê³„
    generateIntegratedPrompt,       // í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±
    cacheAIStatsToRedis,           // Redis AI í†µê³„ ìºì‹±
    
    // ğŸ”§ [NEW] ë‚´ë¶€ í†µê³„ ì ‘ê·¼ (ë””ë²„ê¹…ìš©)
    _getInternalStats: () => ({ ...aiStats }),
    _getCacheContents: () => Array.from(aiResponseCache.keys())
};
